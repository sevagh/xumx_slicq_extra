\documentclass[usenames,dvipsnames]{beamer}
\usetheme{Boadilla}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{multimedia}
\usepackage{fancyvrb}
\usepackage{soul}
\usepackage{multicol}
\usepackage{optparams}
\usepackage{adjustbox}
\usepackage{tikz}
\usetikzlibrary{shapes,positioning}
\newcommand{\foo}{\hspace{-2.3pt}$\bullet$ \hspace{5pt}}
\usepackage{subfig}
\usepackage[
    backend=biber,
    natbib=true,
    sorting=none,
    style=verbose-ibid,
    mincitenames=2,
    maxcitenames=2,
    citestyle=authoryear,
]{biblatex}
\addbibresource{citations_presentation.bib}
\usepackage{pgfpages}
\usepackage{xcolor}
\definecolor{ao(english)}{rgb}{0.0, 0.5, 0.0}
\definecolor{burgundy}{rgb}{0.5, 0.0, 0.13}
%\setbeameroption{show notes}
%\setbeameroption{show notes on second screen=right}
\setbeameroption{hide notes}
\input{variables.tex}

\title{Music demixing with the sliCQ transform}
\author{Sevag Hanssian}
\date{February 18, 2022}
\setbeamertemplate{navigation symbols}{}

\begin{document}

\begin{frame}
\maketitle
\end{frame}

\begin{frame}
	\frametitle{Intro to myself}
	\begin{enumerate}
		\item
			Electrical engineering background, McGill 2014
		\item
			Linux infrastructure engineer at NVIDIA (formerly Pandora, the U.S. music streaming service)
		\item
			Open-source enthusiast: \url{https://github.com/sevagh}, \url{https://gitlab.com/sevagh}
		\item
			Student in the Master of Arts, Music Tech (thesis) program at McGill
		\item
			Member of the Distributed Digital Music Archives \& Libraries lab led by Prof. Ichiro Fujinaga
	\end{enumerate}
\end{frame}

\begin{frame}
	\begin{quote}
	Music source separation is the task of extracting an estimate of one or more isolated sources or instruments (for example, drums or vocals) from musical audio. The task of music demixing or unmixing considers the case where the musical audio is separated into an estimate of all of its constituent sources that can be summed back to the original mixture. The Music Demixing Challenge was created to inspire new demixing research. Open-Unmix (UMX), and the improved variant CrossNet-Open-Unmix (X-UMX), were included in the challenge as the baselines. Both models use the Short-Time Fourier Transform (STFT) as the representation of music signals. The time-frequency uncertainty principle states that the STFT of a signal cannot have maximal resolution in both time and frequency. The tradeoff in time-frequency resolution can significantly affect music demixing results. Our proposed adaptation of UMX replaced the STFT with the sliCQT, a time-frequency transform with varying time-frequency resolution. Unfortunately, our model xumx-sliCQ achieved lower demixing scores than UMX.
	\end{quote}
\end{frame}

\begin{frame}
	\frametitle{Audio source separation}
       \begin{enumerate}
               \item
                       Audio source separation is the task of extracting an estimate of an isolated source from audio, e.g., cocktail party in speech
		       \begin{figure}
		       \includegraphics[width=8cm]{./images-mila-presentation/bss.png}\footnote{\url{https://gowrishankar.info/blog/cocktail-party-problem-eigentheory-and-blind-source-separation-using-ica/}}
		       \vspace{-0.5em}
		       \end{figure}
	       \item
		       Computational source separation has a history of at least 50 years.\footcite{musicmask, musicsepintro1} In computational auditory scene analysis (CASA) and blind source separation (BSS), separate unknown sources
	              \end{enumerate}
\end{frame}

\begin{frame}
	\frametitle{Why speech techniques don't work for music}
       Speech separation algorithm: Independent Component Analysis (ICA)\footcite{musicsepintro1}
       \begin{figure}
	       \vspace{-1.25em}
	       \subfloat{\includegraphics[width=4.5cm]{./images-mila-presentation/ica.png}}\footnote{\url{https://medium.com/appengine-ai/independent-component-analysis-machine-learning-b62ff260c022}}
	       \subfloat{\includegraphics[width=4cm]{./images-mss/positional.png}}
	       \vspace{-0.5em}
       \end{figure}
	ICA in speech applications uses spatial information, requires as many channels as the number of sources, assumes independent sources, and assumes the background is stationary\\
	\vspace{0.15em}
	In music, there are typically more instruments than channels, musical sources are highly dependent, and music is nonstationary and synchronous
\end{frame}

\begin{frame}
	\frametitle{Music source separation}
	\framesubtitle{... is the task of extracting an estimate of one or more isolated sources or instruments from musical audio}
	\begin{itemize}
	       \item
		       Music source separation: extract an estimate of an isolated \textit{known} source from the mix (e.g., harmonic/percussive, vocals, drums), or a source with \textit{known characteristics}, that are dependent \footcite{musicsepintro1}
	       \item
			Popular approach: musical source models, which are ``model-based approaches that attempt to capture the spectral characteristics of the target source'' \footcite[36]{musicsepgood} with time-frequency masks
	\end{itemize}
	\begin{figure}
		\centering
		\vspace{-1.25em}
		\subfloat{\includegraphics[width=5.5cm]{./images-mss/mss1.png}}
		\subfloat{\includegraphics[width=6cm]{./images-mss/mss2.png}}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{Time-frequency masks}
	Multiply the time-frequency (TF) transform (typically, a Short-Time Fourier Transform) with a mask, or a matrix of the same size as the TF transform with values $\in [0, 1]$
	\begin{figure}
		\centering
		\includegraphics[width=12cm]{./images-mss/mask_simple.png}\footnote{\url{https://source-separation.github.io/tutorial/basics/tf_and_masking.html}}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{Estimating time-frequency masks}
	\begin{figure}
		\setcounter{subfigure}{0}
		\vspace{-1em}
		\centering
		\subfloat[Kernel Additive Modeling (KAM) and Nonnegative Matrix Factorization (NMF)]{\includegraphics[width=7.5cm]{./images-mss/kamvnmf.png}}\\
		\vspace{-0.5em}
		\subfloat[Deep neural networks]{\includegraphics[width=7.5cm]{./images-mss/mssdnn.png}}
		\vspace{-0.5em}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{Magnitude and phase spectrogram}
	Common approaches to MSS discard the phase; it's difficult to learn relationships from phase
	\begin{enumerate}
		\item
			Simplifying assumption: estimate magnitude spectrograms, use the phase of the original mixed audio. Called ``noisy phase'' \footcite{noisyphase1}. Done by Open-Unmix (UMX), CrossNet-Open-Unmix (X-UMX) \footcite{umx, xumx}, and many other popular \& near-SOTA models
		\item
			Why? Phase is hard to model!\footnote{\url{https://source-separation.github.io/tutorial/basics/phase.html\#why-we-don-t-model-phase}}
	\end{enumerate}
	\begin{figure}
		\vspace{-0.5em}
	\centering
	\includegraphics[height=3.25cm]{./images-mss/whynophase.png}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{Music demixing (MDX) or unmixing}
	\framesubtitle{... considers the case where the musical audio is separated into an estimate of all of its constituent sources that can be summed back to the original mixture}
	Music demixing (or unmixing): estimate multiple sources (vocals, drums, bass, other\footcite{musdb18hq}) that can be summed back to the original mix. Multiple MSS subproblems, reversing the linear mixing of stems in the recording studio (stem datasets can be used for mixing and demixing)
	\begin{figure}[ht]
		\centering
		\includegraphics[width=12cm]{./images-mss/mixdemix.png}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{MDX ecosystem}
	Evaluation measure: BSS (Blind Source Separation) metrics \footcite{bss, bss2}
	\begin{itemize}
	\item
		\textbf{SDR:} Signal to Distortion Ratio
	\item
		\textbf{SIR:} Signal to Interference Ratio
	\item
		\textbf{SAR:} Signal to Artifacts Ratio
	\item
		\textbf{ISR:} source Image to Spatial distortion Ratio
	\end{itemize}
	Are these good metrics? \footcite{roux2018sdr}, \footnote{MDX @ ISMIR 2021 keynote: Rachel Bittner, ``Source Separation Metrics: What are they measuring?''}\\
	Datasets: MUSDB18-HQ \footcite{musdb18, musdb18hq}; stems: vocals, drums, bass, other\\
	Campaigns: Signal Source Separation Evaluation Campaign (SiSEC) 2016, 2018 \footcite{sisec2016, sisec2018}\\
\end{frame}

\begin{frame}
	\frametitle{MDX, UMX, and X-UMX}
	\framesubtitle{The Music Demixing Challenge was created to inspire new demixing research. Open-Unmix (UMX), and the improved variant CrossNet-Open-Unmix (X-UMX), were included in the challenge as the baselines.}
	MDX: Sony MDX (Music Demixing Challenge) on AICrowd for ISMIR 2021\footnote{\url{https://www.aicrowd.com/challenges/music-demixing-challenge-ismir-2021}}, used SDR to rank systems, introduced a new hidden dataset MXDB21\\\ \\
	UMX: Open-Unmix, a near-SOTA music demixing system based on the STFT with a Bi-LSTM neural network\footcite{umx}. There are four provided pre-trained models for vocals, drums, bass, other\\\ \\
	X-UMX: CrossNet-Open-Unmix, combining four UMX networks for vocals, bass, drums, other with mixed loss functions\footcite{xumx}
\end{frame}

\begin{frame}
	\frametitle{UMX and X-UMX}
	\begin{figure}[ht]
		\centering
		\subfloat{\includegraphics[width=10cm]{./images-blockdiagrams/generic_mdx.png}}\\
		\subfloat{\includegraphics[width=10cm]{./images-blockdiagrams/umx_clean.png}}\\
		\subfloat{\includegraphics[width=10cm]{./images-blockdiagrams/xumx_multiple_targets.png}}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{Time-frequency uncertainty principle}
	The Fourier transform decomposes a signal into a sum of \textbf{infinite} sinusoids: no temporal information\\
	Time and frequency are orthogonal domains (opposites of the Fourier transform), like the position and momentum of an electron
	\begin{figure}
		\includegraphics[height=4cm]{./images-tftheory/gabor13.png}
		\includegraphics[height=2.5cm]{./images-mila-presentation/gabor5.png}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{Joint time-frequency analysis, the STFT, and the spectrogram}
	Joint time-frequency analysis is important for signals whose frequencies change with time\footcite{gabor1946} Take Fourier transform of local windows of the signal
	\begin{figure}
		\includegraphics[height=2cm]{./images-tftheory/gabor3.png}\\
		\includegraphics[height=3.5cm]{./images-mila-presentation/stft_diagram1.png}
		\hspace{-0.75em}
		\includegraphics[height=3cm]{./images-mila-presentation/stft_diagram2.png}\footnote{\url{https://www.mathworks.com/help/signal/ref/iscola.html}}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{The time-frequency uncertainty principle}
	\framesubtitle{... states that the STFT of a signal cannot have maximal resolution in both time and frequency}
	    Time-frequency uncertainty\footcite{gabor1946}:
	    \begin{quote}
		    although we can carry out the analysis with any degree of accuracy in the time direction or frequency direction, we cannot carry it out simultaneously in both beyond a certain limit
	    \end{quote}
	\begin{figure}[ht]
		\centering
		\vspace{-1.5em}
		\subfloat{\includegraphics[height=5cm]{./images-tftheory/gabor2.png}}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{Time-frequency tradeoff}
	\framesubtitle{... can significantly affect music demixing results}
	Time-frequency tiles are constrained to a minimum area: $\Delta t\Delta f \ge 1 $\\Change window size to trade off time and frequency:
	\begin{figure}[ht]
		\centering
		\vspace{-1.5em}
		\subfloat{\includegraphics[height=2cm]{./images-tftheory/gabor3.png} \includegraphics[height=1.75cm]{./images-tftheory/gabor4.png}}\\
		\vspace{-1em}
		\subfloat{\includegraphics[height=2.7cm]{./images-mila-presentation/glock_stft_1024.png}}
		\subfloat{\includegraphics[height=2.7cm]{./images-mila-presentation/glock_stft_4096.png}}
		\subfloat{\includegraphics[height=2.7cm]{./images-mila-presentation/glock_stft_256.png}}
		\vspace{-1.25em}
	\end{figure}
	In music source separation, window size matters per-target.\footcite{tftradeoff1, tftradeoff2} Short-window for percussion, long-window for harmonic
\end{frame}

\begin{frame}
	\frametitle{Time-frequency tradeoff: HPSS case study}
	Harmonic/percussive source separation with median filters\footcite{fitzgerald1}
	\begin{figure}
		\centering
		\includegraphics[height=3.5cm]{./images-mila-presentation/mix_stft_medianfilters.png}\\
		\includegraphics[height=3.5cm]{./images-mila-presentation/harm_stft.png}
		\includegraphics[height=3.5cm]{./images-mila-presentation/perc_stft.png}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{Improving harmonic/percussive source separation (HPSS)}
	\begin{enumerate}
	\item
		From musical and auditory aspects, frequency resolution should increase from high to low frequencies (vice-versa for time resolution)\footcite{cqtransient}
	\item
		Use long windows/$\uparrow \Delta f$ in low frequencies, and short windows/$\uparrow \Delta t$ in high frequencies to analyze music (harmonic basis and transients)\footcite{doerflerphd}
	\item
		window=4096 for harmonic, window=256 for percussive in HPSS\footcite{driedger}
	\item
		Constant-Q Transform (CQT) and multiple STFTs (16384 for harmonic, 1024 for percussive) in HPSS\footcite{fitzgerald2}
	\item
		CQT\footcite{jbrown, klapuricqt} uses long windows in low frequencies and short windows in high frequencies for the 12-tone Western pitch scale
	\end{enumerate}
\end{frame}

\begin{frame}
	\frametitle{Constant-Q Transform}
	Constant-Q transform for music analysis\footcite{jbrown, msp}:
		\begin{enumerate}
			\item
				Harmonics of the fundamental have consistent spacing in the log scale -- the constant pattern\\
				\includegraphics[height=3cm]{./images-mila-presentation/logharmonic.png}
			\item
				Log-frequency spectra, demonstrating the constant pattern for harmonics, would be more useful in musical tasks
		\end{enumerate}
\end{frame}

\begin{frame}
	\frametitle{Constant-Q Transform}
	``Constant ratio of frequency to frequency resolution'': $\frac{f}{\delta f} = Q$
	\begin{figure}
		\setcounter{subfigure}{0}
		\vspace{-1em}
		\centering
		\subfloat[Properties of DFT, CQT]{\includegraphics[height=3.5cm]{./images-tftheory/dftvcqt.png}}
		\subfloat[Window sizes for CQT]{\includegraphics[height=5cm]{./images-tftheory/qwindowchanges.png}}
	\end{figure}
	Non-invertible; approximate inverse introduced\footcite{klapuricqt}
\end{frame}

\begin{frame}
	\frametitle{Constant-Q Transform}
	\begin{figure}
		\setcounter{subfigure}{0}
		\centering
		\subfloat[Discrete Fourier Transform]{\includegraphics[height=3.75cm]{./images-tftheory/violindft.png}}
		\subfloat[Constant Q transform]{\includegraphics[height=3.75cm]{./images-tftheory/violincqt.png}}
		\caption{Violin playing diatonic scale, $G_{3} \text{(196Hz)} - G_{5} \text{(784Hz)}$\footcite{jbrown}}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{NSGT and sliCQT}
	STFT = ``stationary'' Gabor transform: use the same window, suffering from a fixed time-frequency resolution\\
	Nonstationary Gabor Transform (NSGT)\footcite{balazs}, realtime sliCQ Transform\footcite{invertiblecqt, slicq, variableq1} = ``nonstationary'' Gabor transform: use different window sizes to vary the time-frequency resolution\\
	\begin{enumerate}
	\item
		STFT-like transforms with windows that vary with time
	\item
		CQT motivates the NSGT/sliCQ, but can use any monotonically increasing frequency scale (log/cq, mel, Bark, etc.)
	\item
		Outputs the familiar Fourier coefficients with \textbf{perfect inverse}
	\item
		CQT implemented with NSGT/sliCQT = CQ-NSGT
	\end{enumerate}
\end{frame}

\begin{frame}
	\frametitle{NSGT demo}
	\begin{figure}[ht]
		\vspace{-0.5em}
		\setcounter{subfigure}{0}
		\subfloat[6ms STFT]{\includegraphics[height=3.15cm]{./images-tftheory/tf_tradeoff_balasz1.png}}
		\subfloat[93ms STFT]{\includegraphics[height=3.15cm]{./images-tftheory/tf_tradeoff_balasz2.png}}\\
		\vspace{-0.5em}
		\subfloat[6--93ms NSGT]{\includegraphics[height=3.15cm]{./images-tftheory/tf_tradeoff_balasz3.png}}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{STFT vs. CQ-NSGT}
	\begin{figure}[ht]
		\setcounter{subfigure}{0}
		\centering
		\vspace{-1em}
		\subfloat[STFT, window = 256]{\includegraphics[height=2.4cm]{./images-gspi/glock_stft_256.png}}
		\subfloat[STFT, window = 1024]{\includegraphics[height=2.4cm]{./images-gspi/glock_stft_1024.png}}
		\subfloat[STFT, window = 4096]{\includegraphics[height=2.4cm]{./images-gspi/glock_stft_4096.png}}
		\vspace{-0.5em}
		\subfloat[CQT, 12 bins/octave]{\includegraphics[height=2.4cm]{./images-gspi/glock_cqt12.png}}
		\subfloat[CQT, 24 bins/octave]{\includegraphics[height=2.4cm]{./images-gspi/glock_cqt24.png}}
		\subfloat[CQT, 48 bins/octave]{\includegraphics[height=2.4cm]{./images-gspi/glock_cqt48.png}}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{xumx-sliCQ: spectral transform}
	\framesubtitle{Our proposed adaptation of UMX replaced the STFT with the sliCQT, a time-frequency transform with varying time-frequency resolution}
	Hypothesis: improve Open-Unmix by using sliCQT with varying time-frequency resolution. sliCQT demonstrates good tonal/transient representation, and displays more musical information than the STFT\\\ \\
	Choose sliCQT params by maximizing SDR of ``noisy phase'' oracle: $\hat{X}_{\text{target}} = |X_{\text{target}}| \cdot \measuredangle{X_{\text{mix}}}$; \textbf{7.42 dB} vs. 6.23 dB of STFT-4096 on MUSDB18-HQ validation set
	\begin{figure}[ht]
		\centering
		\vspace{-0.5em}
		\includegraphics[height=3.5cm]{./images-mila-presentation/spectrograms_comparison.png}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{Ragged shape of the sliCQT}
	sliCQT output: list of complex 2D $\text{Time} \times \text{Frequency}$ tensors of Fourier coefficients, bucketed by time resolution. Different temporal frame rate per bucket
	\begin{figure}
		\centering
		\includegraphics[height=3.7cm]{./images-blockdiagrams/stftslicqtcmp1.png}
		\hspace{-0.25em}
		\includegraphics[height=4.5cm]{./images-blockdiagrams/stftslicqtcmp2.png}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{3D shape of the sliCQT}
	sliCQT returns coefficients for sliced input signal: ``slicing windows are symmetrically zero-padded to length 2N , reducing time-aliasing significantly'' \footcite[10]{slicq}. Overlap-add each slice by 50\%:
	\begin{quote}
		Displaying the framewise transform is slightly more tricky as we have to overlap-add the spectrograms obtained for each frame... Note that it is not possible to synthesize the audio from this overlapped version as we cannot retrieve the analysis frames from it.\footnote{\url{https://mtg.github.io/essentia-labs/news/2019/02/07/invertible-constant-q/}}
	\end{quote}
	\begin{figure}
		\centering
		\includegraphics[height=2cm]{./images-blockdiagrams/slicq3ddatastructure.png}\\
		\includegraphics[height=1.5cm]{./images-blockdiagrams/slicq2ddatastructure.png}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{xumx-sliCQ: CDAE network architecture}
	Use Convolutional Denoising Autoencoder (CDAE) \footcite{plumbley1, plumbley2} neural architecture, applied to each matrix of the ragged overlap-added sliCQT separately
	\begin{figure}
		\vspace{-0.25em}
		\centering
		\includegraphics[height=3cm]{./images-blockdiagrams/xumx_slicq_cdae.png}
		\vspace{-0.25em}
	\end{figure}
	Introduce an extra layer for ``de-overlap''
	\begin{figure}
		\vspace{-0.25em}
		\centering
		\includegraphics[height=3cm]{./images-blockdiagrams/xumx_slicq_pertarget_largefont.png}
		\vspace{-0.25em}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{xumx-sliCQ: block diagrams, results}
	\begin{enumerate}
		\item
			My goal: improve Open-Unmix by replacing STFT with sliCQT
		\item
			Scored 3.6 dB vs. 4.6 dB (UMX) and 5.54 dB (X-UMX); there is still room for improvement
	\end{enumerate}
	\begin{figure}[ht]
		\centering
		\vspace{-1.15em}
		\subfloat{\includegraphics[width=9cm]{./images-blockdiagrams/generic_mdx.png}}\\
		\vspace{-0.5em}
		\subfloat{\includegraphics[width=9cm]{./images-blockdiagrams/umx_clean.png}}\\
		\vspace{-0.5em}
		\subfloat{\includegraphics[width=9cm]{./images-blockdiagrams/xumx_slicq_clean.png}}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{MDX 21 winners, current trends in demixing}
	\begin{enumerate}
		\item
			Previously, music demixing systems were submitted to and evaluated at SiSEC (Signal Separation Evaluation Campaign). This year: MDX (Music Demixing Challenge) ISMIR 2021 @ AICrowd, follow-up MDX21 workshop, satellite @ ISMIR 2021
		\item
			\textbf{ISMIR 2021}: Model that uses the complex spectrogram (i.e. includes phase) and uses complex masks\footcite{kong2021decoupling}
		\item
			\textbf{MDX21}: 1: Demucs++\footcite{demucsplus} (waveforms + complex spectrogram), 2: KUIELAB-MDX-Net \footcite{choi2021} (waveforms + magnitude spectrogram), 3: Danna-Sep\footcite{dannasep} (waveform + magnitude spectrogram, use complex spectrogram in loss function)
	\end{enumerate}
	Properties in common: blending networks, waveforms (implicitly includes phase), complex spectrograms/masks, mixing spectrogram and waveform models
\end{frame}

\begin{frame}
	\frametitle{Magnitude mask above 1}
	Common approaches to music source separation (MSS):
	\begin{enumerate}
		\item
			Get spectrogram of mix
		\item
			Take magnitude
		\item
			Multiply by a mask $\in [0, 1]$ to get source estimate
		\item
			Why $[0, 1]$? DFT/STFT is a linear operation: $x_{a} = x_{b} + x_{c}, |X_{a}| = |X_{b}| + |X_{c}|$\\
			$|X_{b}| = M_{b}(\in [0, 1]) \times |X_{a}|$\\
			if $M_{b}$ (i.e., Mask of source b) $> 1$, then $|X_{b}| > |X_{a}|$?
	\end{enumerate}
	\begin{figure}
	\centering
	\includegraphics[height=3cm]{./images-mss/mask_simple.png}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{Phase!}
	Common approaches to MSS discard the phase; it's difficult to learn relationships from phase
	\begin{figure}
	\centering
	\includegraphics[height=3cm]{./images-mss/whynophase.png}
	\end{figure}
	This paper considers the phase, and uses a complex mask to estimate the magnitude and phase of the spectrogram\\
	$|X_{b}| = M_{b}(\in [0, 1]) \times |X_{a}|$\\
	if $M_{b}$ (i.e., Mask of source b) $> 1$, then $|X_{b}| > |X_{a}|$?
	\textbf{Yes!} 
	\begin{quote}
		|M(t,f)| can be larger than 1... this may happen when S(t,f) and N(t,f) are out of phase, since that makes the magnitude of mixture to be smaller than that of (individual) signal
	\end{quote}
\end{frame}

\begin{frame}
	\frametitle{Sound samples}
	``Winners'' of MDX21 (didn't release their code/data, so they didn't get a prize; proprietary company):
	\url{https://www.youtube.com/watch?v=fNgIXBErUMI}
\end{frame}

\end{document}
