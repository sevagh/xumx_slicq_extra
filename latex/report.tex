\documentclass[letter,12pt,notitlepage]{article}
\usepackage[left=4cm, right=2.5cm, top=2.5cm, bottom=2.5cm]{geometry}
\usepackage[shortlabels]{enumitem}
\usepackage{graphicx}
\usepackage{todonotes}
\usepackage{amsmath}
\usepackage[titletoc,title]{appendix}
\usepackage{amssymb}
\usepackage{makecell}
\usepackage{pdfpages}
\usepackage{wrapfig}
\usepackage{verbatim}
\usepackage{listings}
\usepackage{minted}
\usepackage{subfig}
\usepackage{titling}
\usepackage[compatibility=false]{caption}
\usepackage[parfill]{parskip}
\setlength{\droptitle}{1cm}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}
\usepackage{setspace}
\renewcommand{\topfraction}{0.85}
\renewcommand{\textfraction}{0.1}
\renewcommand{\floatpagefraction}{0.75}
\usepackage[
    %backend=biber, 
    natbib=true,
    style=numeric,
    sorting=none,
]{biblatex}
\addbibresource{citations.bib}
\input{variables.tex}

\setcounter{biburllcpenalty}{7000}
\setcounter{biburlucpenalty}{8000}

\newenvironment{tight_enumerate}{
\begin{enumerate}
  \setlength{\itemsep}{0pt}
  \setlength{\parskip}{0pt}
}{\end{enumerate}}

\newenvironment{tight_itemize}{
\begin{itemize}
  \setlength{\itemsep}{0pt}
  \setlength{\parskip}{0pt}
}{\end{itemize}}

\newlength{\mintednumbersep}
\AtBeginDocument{%
  \sbox0{\tiny00}%
  \setlength\mintednumbersep{8pt}%
  \addtolength\mintednumbersep{-\wd0}%
}

\title{\ThesisTitle}

\author{\vspace{1em}\\Sevag Hanssian \\
  McGill University \\
 \small{\texttt{sevag.hanssian@mail.mcgill.ca}} \\
 \small{\texttt{sevagh@protonmail.com}} \\\ \\\ \\
 \small{Thesis for Master of Arts in Music Technology}\\
 \small{Date TBD, 2021}}

% nil out the auto date
\date{}

\begin{document}

\maketitle

\vspace{3.5em}

\begin{abstract}
	The short-time Fourier transform (STFT) is an important tool for the time-frequency analysis of acoustic signals. The STFT is commonly used as the input representation of music signals in deep learning models. Examples of music information retrieval (MIR) tasks where such models have achieved success are onset detection, beat tracking, and music source separation. Despite its ubiquity, the STFT has a fixed and bounded time-frequency resolution, such that one must sacrifice time for frequency resolution (or vice versa) by changing the window size. The Nonstationary Gabor Transform (NSGT) is an adaptive time-frequency transform which can vary its time-frequency resolution to better represent music signals. In this thesis, first the STFT and NSGT are described as tools for representing and manipulating music signals. Next, the STFT is replaced with different configurations of the NSGT in deep learning models for onset detection, beat tracking, and music source separation respectively, showing significant improvements in the results.
\end{abstract}

\vfill
\clearpage %force a page break

\tableofcontents

\vfill
\clearpage %force a page break

\listoffigures

\listoflistings

\vfill
\clearpage %force a page break

\section{Introduction}
\label{sec:intro}

\subsection{Motivation}

The study of acoustic signals forms the core of many fields including sonar, seismology, audio, music, and speech. Acoustic signals are functions of time, representing the evolving amplitude of the pressure wave. Another way to characterize acoustic signals is by their frequency components. The Fourier transform decomposes time-domain signals into their constituent frequency components, by means of a sum of sinusoids that oscillate infinitely in time -- in other words, the Fourier transform gives us knowledge of which frequencies are present in a signal, with no temporal information. However, many important signals such as speech and music contain frequency components that evolve with time, such as the basic melody.

For this class of signal, joint time-frequency analysis is an important tool. Time-frequency analysis is performed by multiplying the signal being studied by finite, consecutive windows of a short duration, and performing a Fourier analysis of each windowed section. This is also referred to as the short-time Fourier transform (STFT), and the output of the STFT is visually represented as a spectrogram. Since time and frequency are Fourier duals of each other, time-frequency analysis is subject to the Heisenberg uncertainty principal \todo{cite me}. This means that when performing time-frequency analysis, one cannot be arbitrarily precise in both time and frequency, and must trade one for the other by varying the duration of the STFT window.

Musical signals have characteristics that lead to conflicting requirements in the STFT. In the low frequency region, music needs to be analyzed with long-duration windows for a high, or fine, frequency resolution -- notes in the low frequencies lay the harmonic basis of a song, and this is also reflected by the psychoacoustic system and cochlea, which can separate low frequencies more finely than high frequencies. Conversely, the high frequency region contains transients and broadband sounds, which are useful for timbre identification and rhythm. These transients have fast attacks and decays and need to be analyzed with short-duration windows.

The Constant-Q transform (CQT), first proposed by \textcite{jbrown} and refined by \textcite{klapuricqt}, is a time-frequency transform obtained by varying the window size by frequency region, designed for musical signals by operating on a log frequency scale. Recent work by \textcite{balazs} resulted in the creation of time-frequency transforms with perfect inversions and arbitrary frequency scales, called the Nonstationary Gabor transform (NSGT). The NSGT is flexible and can be used to analyze signals with a logarithmic or Western pitch scale (i.e., the CQT or CQ-NSGT), or other useful frequency scales such as the Mel and Bark psychoacoustic scales.

Most recently, deep learning solutions for music information tasks have achieved state-of-the-art results, such as Bock's onset detection and beat tracking algorithms, and Open-Unmix for music source separation, based on the spectrogram. On the other hand, direct waveform models are achieving success, bypassing the difficulty of choosing an optimal TFR/latent space representation with the STFT window size.

The motivation for this thesis is to replace the STFT-based spectrogram with different configurations of the NSGT in deep learning solutions in two problem spaces -- in onset detection and beat tracking, and in music source separation.

\subsection{Thesis objective}

The main objective of this thesis is to demonstrate the viability of swapping the STFT with NSGT in spectrogram-based algorithms or machine learning models for MIR. My hypothesis is that by choosing the appropriate parameters for the NSGT to suit the specific task, one can achieve better performance than using the standard STFT. This could also represent a way to retrofit or improve previous state-of-the-art models without significantly changing the model architecture, and surpassing the trend of new end-to-end waveform models such as Demucs.

\subsection{Related work}

\subsection{Contribution and results}

\subsection{Outline}

This thesis is organized as follows. Section \ref{sec:theorystandard} will cover the theory of the DFT and its fast FFT implementation, and their use in music systems. Section \ref{sec:theoryvariant} will describe several variants of the FFT that may be useful for music applications. Section \ref{sec:libraries} will describe and benchmark existing open-source FFT libraries, and develop a new FFT library containing implementations of the studied variants. Section \ref{sec:results} will describe the outputs and performance analysis of the variants in the new library, as well as results achieved in a real-world music system by substituting the standard FFT with each variant. Finally, section \ref{sec:conclusion} will discuss the findings and explore whether there is value in using a variant instead of the standard FFT when creating new music systems.

\vfill
\clearpage

\section{Short-time Fourier transform}
\label{sec:theorystft}

\vfill
\clearpage

\section{Nonstationary Gabor transform}
\label{sec:theorynsgt}

\subsection{Theoretical background}

\todo[inline]{frame theory and shit}

\subsection{Irregular time and frequency sampling}

\todo[inline]{arbitrary f scales and time scales}

\subsection{Code implementation and computation cost}

\todo[inline]{how many windows, how many FFTs}

\subsection{Output coefficients and dimensions}

\todo[inline]{whats the output, what does it mean, how does it relate to the FFT coefficients, time-frequency matrix}

\subsection{Common frequency scales and examples}

\subsubsection{Constant-Q transform with the log scale}

\subsubsection{Variable-Q transform}

\subsubsection{Mel and Bark}

\vfill
\clearpage

\section{Onset detection and beat tracking}
\label{sec:beattrack}

\vfill
\clearpage

\section{Music source separation}
\label{sec:musicsep}

\subsection{Task definition and survey}

The task of music source separation is to split a mixed song into its constituent components, or sources. \citet{musicsepgood} describe that music source separation could operate on the level of instruments, or for broader categories of sources, grouped into harmonic, percussive, and singing voice.

Surveys on speech \cite{speechmask} and music separation \cite{musicmask} indicate that the majority of separation algorithms use the technique of time-frequency masking (or spectral masking) to separate the sources.

\begin{wrapfigure}{r}{8cm}
	\vspace{-1.0em}
	\includegraphics[width=8cm]{./maskdemo.png}
	\caption{Results of a soft and hard oracle mask applied for speech denoising. The oracle mask is the ideal mask for a given signal -- to compute it, the target and interference signals must be known.}
	\label{fig:masks}
	\vspace{-1.5em}
\end{wrapfigure}

\citet{masking} describe different time-frequency masking strategies in audio source separation. A time-frequency mask (or spectral mask, or masking filter) is a matrix of the same size as the complex STFT, by which the STFT is multiplied to mask, filter, or suppress specific time-frequency bins. A soft mask has real values $\in [0.0, 1.0]$, and a binary or hard mask has logical values, i.e., only 0 and 1. The soft mask used in \cite{fitzgerald1, fitzgerald2} is a Wiener filter given in the following equation, where $\hat{S}$ represents the complex-valued spectrogram:
\[ M_{\text{target}} = \frac{|\hat{S}_{\text{target}}|^{2}}{|\hat{S}_{\text{interference}}|^{2} + |\hat{S}_{\text{target}}|^{2}} \]

Soft masks generally produce higher quality sound. An illustration of spectral masking is shown in figure \ref{fig:masks}.

Most recently, the SigSep\footnote{\url{https://sigsep.github.io/}} community has been running the Signal Separation Evaluation Campaign (SISEC), which sets the tone for the modern state-of-the-art models. SiSec uses the BSS (Blind Source Separation) Eval \cite{bss} objective measure for separation quality, or BSSv4 variant.

The most popular music stem dataset used by SISEC and SigSep is the MUSDB18 dataset \cite{musdb18} (or the HQ, high-quality, equivalent \cite{musdb18-hq}). MUSDB18-HQ contains stereo wav files sampled at 44100 Hz representing stems (drum, vocal, bass, and other) from a collection of permissively licensed music, specifically intended for recording, mastering, mixing (and in this case, ``de-mixing'', or source separation) research.

In modern music source separation, the stems of MUSDB18 have determined the four most common sources to separate -- drums, bass, vocals, and other. SigSep's own network, Open-Unmix, is trained only on MUSDB18, and produces near-state-of-the-art results. The absolute state-of-the-art crown is jointly held by Conv-Tasnet and Demucs, both of which surpass Open-Unmix. Both models operate directly on the waveform domain, which indicates that they could surpass the maximum possible poerformance of time-frequency masking approaches, as is done in speech separation. However, in practise they are still below the limits of masking-based approaches.

\subsection{Surpassing the STFT ideal oracle mask}

The first experiment to run is to discover which configuration of the NSGT has the potential to surpass the maximum performance of time-frequency masking using the spectrogram. Given ground truth data, such as what is available in MUSDB18, we have available to us the individually recorded sources for each track. From this, we can compute the ideal or oracle masks::

\begin{flalign}
	\nonumber \text{given: } & x_{\text{drums}}, x_{\text{vocals}}, x_{\text{bass}}, x_{\text{other}}\\
	\nonumber & x_{\text{mix}} = \sum{x}\\
	\nonumber & \hat{X} = \text{STFT}(x), \text{complex-valued}\\
	\nonumber & |\hat{X}|^{\alpha} = \text{magnitude STFT of } x \text{ raised to } \alpha \text{ power, real-valued}\\
	\nonumber & \text{Mask}_{\text{source}} = \frac{|\hat{X}|_{\text{source}}^{\alpha}}{\sum{|\hat{X}|^{\alpha}}}\\
	\nonumber & \hat{Y}_{\text{source}} = \text{Mask}_{\text{source}} * \hat{X}_{\text{mix}}\\
	\nonumber & y = \text{ISTFT}(\hat{Y})\\
	\nonumber & y = \text{ideal estimate of } x
\end{flalign}

Finally, using these pairs of $x, y$, we can get the maximum possible BSS metrics of any algorithm or model based on time-frequency masking. This is the methodology used to find the so-called oracle estimator or oracle mask, which represents the maximum possible performance of any algorithm or model for music source separation that uses spectrogram masking (CITE UMX, etc.).

Approaching or surpassing the ideal mask performance is a common benchmark in source separation literature. \todo{weak} Demucs talks about it but doesn't achieve it.

\subsubsection{BSS and NSGT performance optimizations}

\subsubsection{Evaluated NSGT parameters}

The space of possible NSGT parameters is large. First, there are multiple frequency scales to choose from -- the log (or octave) scale is the case of the CQT, but the NSGT can also use the Mel and Bark psychoacoustic scales. For the frequency bins, the original CQT papers \cite{klapuricqt, invertiblecqt} use multiples of 12 bins or pitches per octave (based on the 12-tone pitch scale), and use one or many octaves, leading to CQTs with 12-96 frequency bins in steps of 12. When using the Mel or Bark scales however, there is no need to continue with the 12-tone pitch per octave strategy, since we are already departing from music theory. Also, bins above 96 are not described in the literature, but without a good justification. Therefore, the range of bins evaluated are integers between 12-348, not just multiples of 12.

The minimum and maximum frequencies of the scales are also configurable. To eliminate one parameter from the evaluation, the maximum frequency was fixed at 22050 Hz, or the Nyquist rate, half of the sampling rate of 44.1 kHz in MUSDB18-HQ. The minimum frequency is varied between 15-60 Hz (below the 20 Hz limit of human hearing\todo{citeme}, up to 60 Hz to include the value of 57 Hz used in \cite{klapuricqt}). Finally, the variable-Q log scale introduces the additional parameter of $\gamma$ for the frequency offset, which is varied between 0-100 Hz.

The BSS evaluation is computationally expensive -- for an average track in MUSDB18-HQ, it takes 30 seconds to compute all of the BSS metrics, even after the significant performance optimizations described previously. For a more fair evaluation, 3 separate randomly-selected tracks from the MUSDB18-HQ test set are considered (with a fixed random seed for consistency). We would prefer to find an NSGT configuration that performs best across multiple tracks, and not overfit to one particular song. For 3 songs, the BSS evaluation of the ideal magnitude ratio mask for a single configuration of NSGT therefore takes 1.5 minutes. Although there are 4 possible types of oracle mask based on spectrograms (ideal magnitude binary mask, ideal power binary mask, ideal magnitude ratio mask, ideal power ratio mask), for the optimization process the most common case of ideal ratio magnitude mask is used.

With all of this information in mind, an exhaustive grid search across all NSGT configurations is not feasible. The Bayesian optimization technique \cite{bayesian} was selected, as it is ``an approach to optimizing objective functions that take a long time (minutes or hours) to evaluate'' and ``best-suited for optimization over continuous domains of less than 20 dimensions.'' The open-source Python library \textit{BayesianOptimization}\footnote{\href{https://github.com/fmfn/BayesianOptimization}{https://github.com/fmfn/BayesianOptimization}} was used in the testbench implementation.

The Bayesian optimization process considers a black-box function (that being optimized) which takes varying input parameters and outputs a single scalar value. The function was designed to accept the configuration of the NSGT as an input, and return a single scalar value representing the median SDR score with the ideal magnitude ratio mask across all 4 MUSDB18-HQ targets (drums, vocals, bass, other) and across the 3 tracks. A different value can be returned to target different aspects of source separation performance -- for example, one could optimize on the SAR if their primary goal is to reduce artifacts. However, SDR is the most commonly used single-value metric to demonstrate overall source separation effectiveness in literature.

The Bayesian optimization process can additionally perform some random parameter selections in the beginning, to help improve the subsequent iterative optimization. Table \ref{table:nsgtparamsirm} contains the parameter ranges of the evaluated NSGT configs and the number of Bayesian optimization iterations. Table \ref{table:nsgtbayesresults} shows the best configurations selected by the optimization process, compared to the control ideal ratio magnitude mask performance of the STFT with a window size of 2048.

\begin{table}[ht]
	\centering
\begin{tabular}{ |l|l|l|c|c|c| }
	 \hline
	  Scale & Parameters & Random iter & Optimization iter \\
	 \hline
	 \hline
	 VQ-Log & 12-348 bins, 15-60 Hz fmin, 0-100 Hz $\gamma$ & 20 & 180 \\
	 \hline
	 CQ-Log & 12-348 bins, 15-60 Hz fmin & 20 & 180 \\
	 \hline
	 Mel & 12-348 bins, 15-60 Hz fmin & 20 & 180 \\
	 \hline
	 Bark & 12-348 bins, 15-60 Hz fmin & 20 & 180 \\
	 \hline
\end{tabular}
	\caption{NSGT parameter ranges evaluated by Bayesian optimization}
	\label{table:nsgtparamsirm}
\end{table}

\begin{table}[ht]
	\centering
\begin{tabular}{ |l|l|l|c|c|c| }
	 \hline
	  Transform & Parameters & IRM1 SDR \\
	 \hline
	 \hline
	 STFT (control) & window = 2048 & 180 \\
	 \hline
	 NSGT, CQ-Log & 138 bins, 47.3 Hz fmin & 7.2 \\
	 \hline
	 NSGT, VQ-Log & 134 bins, 47.3 Hz fmin, 1.7 Hz gamma & 7.2 \\
	 \hline
	 NSGT, Mel & 263 bins, 24.9 Hz fmin & 7.44 \\
	 \hline
	 NSGT, Bark & 239 bins, 30.1 Hz fmin & 7.45 \\
	 \hline
\end{tabular}
	\caption{Best NSGT configurations selected by Bayesian optimization}
	\label{table:nsgtbayesresults}
\end{table}

\subsubsection{NSGT oracle mask results}

\begin{figure}[ht]
	\centering
%\includepdf[pages=-,pagecommand={},width=\textwidth]{oracle_boxplot.pdf}
\makebox[\textwidth]{\includegraphics[width=15cm]{./oracle_boxplot.pdf}}
\caption{Music separation results for NSGT oracle masks}
\label{fig:nsgtboxplots}
\end{figure}

\subsection{Open-Unmix-NSGT}

\todo[inline]{better hope umx shines here}

\subsubsection{Open-Unmix}

\subsubsection{NSGT adaptation}

\subsubsection{Results}

\vfill
\clearpage

\section{Conclusions}
\label{sec:conclusion}

foo

\subsection{Evaluation}

foo

\subsection{Outlook}

foo

\subsection{Summary}

foo

\vfill
\clearpage % force a page break before references

%\nocite{*}
\section{References}
\printbibliography[heading=none]

\vfill
\clearpage %force a page break

\begin{appendices}

\section{Code availability and replicating the results}
\label{appendix:coderesultsrepro}

\end{appendices}

\end{document}
