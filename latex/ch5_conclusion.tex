\documentclass[report.tex]{subfiles}
\begin{document}

\section{Conclusion}
\label{sec:conclusion}

\subsection{Discussion}

The creation of xumx-sliCQ led to several contributions to the current Python ecosystem for music demixing. First, the GPU-accelerated BSS metrics evaluation will be useful for as long as BSS is used in large-scale evaluations of music demixing systems, and it was showed that \textasciitilde2-2.5x time savings can be expected. Second, the PyTorch implementation of the forward and backward NSGT and sliCQT, in both the zero-padded matrix and ragged forms, will allow the NSGT/sliCQT to be used in different GPU-based machine learning and deep learning networks.

The proposed model, xumx-sliCQ, failed to beat Open-Unmix (UMX). It was \textasciitilde4.9x smaller on disk than UMX, but was \textasciitilde2x slower on average to process a song. The median SDR on the test set of MUSDB18-HQ was 3.6 dB, compared to the 4.64 dB of UMX. Additionally, there is a configuration of xumx-sliCQ to improve the performance to 3.71 dB by performing the Wiener-EM post-processing on the sliCQT instead of the STFT, at the cost of being \textasciitilde4x slower than UMX.

In early experiments, the neural networks were designed to use the matrix form of the transform, but the dB SDR score of the music demixing results were always below 0. This indicated that the neural network could not learn how to demix from the matrix form representation of the sliCQT. After discussing this limitation with colleagues, it was suggested that the zero-padding of the time coefficients in the low-frequency regions to match the high-frequency regions could make it difficult for the network to learn. The ragged form of the transform achieved positive SDR scores for the first time, and was improved up to the final score of 3.6 dB. The result showed that the ragged sliCQT could replace the STFT in a neural network.

\textcite{variableq1}'s proposed variant of the NSGT/sliCQT is the leading implementation of the NSGT, and it is used in the MATLAB CQT (CQ-NSGT) function from the MATLAB Wavelet Toolbox.\footnote{\url{https://www.mathworks.com/help/wavelet/ref/cqt.html}} The problem of the zero-padded matrix form is addressed with rasterization, or interpolation, of the low-frequency bins to match the larger size of time coefficients of the high-frequency regions, rather than zero-padding. The paper also proposed to improve the phase of the transform, which may affect the quality of the first waveform estimate from the mix-phase inversion.

After the completion of this thesis, my opinions on the most promising future directions of research are:
\begin{tight_enumerate}
	\item
		Incorporating the ideas from \textcite{variableq1}, including the rasterization/interpolation instead of zero-padding for the matrix form, into the PyTorch NSGT/sliCQT library\footnote{\url{https://github.com/sevagh/nsgt}}
	\item
		Picking sliCQT parameters by a different strategy than the mix-phase inversion (MPI) oracle. For example, there may be a sliCQT representation which a neural network can learn from more effectively, but doesn't score highly on the MPI oracle.
	\item
		Designing a different neural network architecture. If the rasterized/interpolated matrix form is more promising than the zero-padded matrix form, this would simplify the network design compared to the current ragged form. However, even if we continue using the ragged form of the transform, there are still many network architectures that can be tried that may be better than the one used in this thesis.
\end{tight_enumerate}

A design constraint of X-UMX is that the spectrograms for the 4 targets to have the same shape so that they can be summed in the frequency-domain combination loss. This ruled out an early experiment with different sliCQT parameters per-target. The STFT-based Wiener-EM step is compatible with the multi-sliCQT idea, since the different sliCQTs are swapped into the STFT domain for the iterative refinement step. Similarly, the frequency-domain combination losses of X-UMX can potentially be computed with the STFT after getting the per-target magnitude sliCQT estimates. This way, the improved loss functions of X-UMX would still be compatible with 4 independent sliCQT networks per-target.

\subsection{Summary and outlook}

The STFT has known limitations that arise from its fixed time-frequency resolution. Methods of spectral music demixing that use the STFT have addressed this limitation by using multiple STFTs or by using different time-frequency transforms like the CQT. Time-domain waveform models, or end-to-end models (\cite{waveunet, demucs, endtoend}), are achieving success as an alternative to spectral models.

Recall that in spectral models for source separation, the phase is commonly discarded. According to \textcite{endtoend}, attempts to use the phase of the spectrogram could not beat magnitude spectral models, and waveform models have surpassed both since the waveform implicitly contains the phase.

The goal of using the sliCQT in a music demixing application was to see if the improved time-frequency resolution characteristics compared to the STFT and an appropriately-chosen frequency scale of analysis could squeeze out more performance from simple magnitude spectrogram models. The resulting neural network showed that it could perform the task of music demixing, but the final trained model could not surpass the original STFT model that it was based on.

The power of the sliCQT is that it can provide a method for computing a time-frequency transform with the familiar complex-valued Fourier coefficients and a perfect inverse operation for arbitrary frequency scales. The signal or application under study can dictate the frequency scale used. The potential uses of the sliCQT can be much wider than xumx-sliCQ, and it is the hopes of the author that other researchers explore the sliCQT and see what they can achieve with it.

\newpagefill

\subsection{ISMIR 2021 Music Demixing Challenge}

From the first time I saw the median-filtering harmonic/percussive source separation (HPSS) algorithm of \textcite{fitzgerald1}, I have been fascinated with music demixing. This culminated in a series of projects where I explored different aspects of music demixing, including realtime HPSS,\footnote{\url{https://github.com/sevagh/Real-Time-HPSS},\url{https://github.com/sevagh/Zen}} various time-frequency explorations including the NSGT and sliCQT,\footnote{\url{https://github.com/sevagh/Music-Separation-TF}} and a convolutional neural network for music demixing using the NSGT.\footnote{\url{https://github.com/sevagh/MiXiN}}

During these projects, I gradually discovered the SigSep community\footnote{\url{https://github.com/sigsep}} and their collection of open-source tools around music demixing, including Open-Unmix (\cite{umx}), the MUSDB18-HQ loader, BSS metrics evaluator, and more (all of which were used and mentioned throughout this thesis).

From around April 2021, I considered a tentative thesis topic where I looked for an alternative time-frequency transform to the STFT. The intention was to improve the results of an STFT-based neural network by simply swapping one time-frequency matrix with another. Open-Unmix was the natural starting point, for its open-source design and intention to be used as a base for future research.

Coincidentally, the ISMIR 2021 Music Demixing Challenge (MDX) began in May.\footnote{\url{https://www.aicrowd.com/challenges/music-demixing-challenge-ismir-2021}}  ISMIR (International Society for Music Information Retrieval) 2021 is the upcoming conference for the leading organization for music information retrieval (MIR) research. The MDX is a digital contest for music demixing systems that ran between May--August 2021, with a hidden new dataset for music demixing (MXDB21) created in-house by Sony, one of the main sponsors. The competition was organized with the help of AICrowd,\footnote{\url{https://www.aicrowd.com/}} a platform for crowdsourced AI and data science competitions.

Throughout the competition, I focused on submitting improved versions of my UMX/sliCQT experiments, making 38 total submissions by the end. The organization of the competition was excellent, and the motivational and helpful atmosphere allowed me to make more progress than I ever expected. I am grateful for it, and happy to have participated in it. Without it, this thesis would not have been possible.

Finally, I'm pleased to announce that from my participation in the MDX, the creator of a royalty-free music project\footnote{\url{https://open.spotify.com/artist/7IYLENV1pGGPvL6wkyl7t5}} agreed to release the stems in the interest of music research as an open dataset\footnote{\url{https://github.com/OnAir-Music/OnAir-Music-Dataset}} licensed permissively under Creative Commons.

\end{document}
