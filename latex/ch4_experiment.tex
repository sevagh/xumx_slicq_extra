\documentclass[report.tex]{subfiles}
\begin{document}

\chaptertodo{
do boxplot for different sizes of STFT vs. chosen sliCQ - with cupy thing\\
selected spectrograms showing the sliCQ transform vs. the STFT\\
table of network learning parameters etc. from those repos (and scripts/train.py defaults)\\
}

\newpagefill

\section{Experiment}

\subsection{sliCQ transform performance analysis}

\subsection{sliCQ transform parameter search}

\subsubsection{Comparing different sliCQ and STFT configurations}

\ichfeedback{I don't love the title here but what i mean is i want to pick, as we discussed, multiple STFT window sizes e.g. 512 1024 2048 4096 8192, and multiple sliCQ configurations e.g. Bark, Mel, 33Hz, 57Hz, 200 bins, 500 bins, 12 bins and contrast them all side by side - visual spectrograms, describe the time-frequency resolution, etc.}

\ichfeedback{if you pick a bad scoring config, e.g. Constant-Q Log scale with 14 frequency bins and frequency limits 12.3 Hz -- 22050 Hz, you can get an oracle score of -7 dB SDR (completely terrible performance - i've seen it happen), and if you pick a good one, you get +8.9 dB SDR (surpassing the STFT)}

\ichfeedback{it would be good to plot the magnitude and phase of the good and bad slicq. most likely the ``bad'' one is losing phase information when we ignore its phase. something must be controlling why a few hz in either direction is causing such a dramatic SDR difference}

\subsection{Neural network training}

The training parameters of xumx-sliCQ were kept similar to Open-Unmix and CrossNet-Open-Unmix:

The training curves can be seen in figure \ref{fig:networkloss}. These were taken from Tensorboard,\footnote{\url{https://www.tensorflow.org/tensorboard}} which is a visual web component of the Tensorflow deep learning framework (\cite{tensorflow, tensorflowsoft}) that is also compatible with PyTorch. It was used to visualize the loss curves of xumx-sliCQ during training.

\begin{figure}[ht]
	\centering
	\subfloat[Train loss]{\includegraphics[width=\textwidth]{./images-neural/train_loss.png}}
	\hspace{0.5em}
	\subfloat[Validation loss]{\includegraphics[width=\textwidth]{./images-neural/valid_loss.png}}
	\caption{Tensorboard loss curves for xumx-sliCQ, 1000 epochs}
	\label{fig:networkloss}
\end{figure}

\subsection{Demixing results}

The BSSv4 scores for the demixing results, computed on the MUSDB18-HQ (\cite{musdb18hq}) dataset's test split, are shown in figure \ref{fig:bssboxplot}. Table \ref{table:bsseval} contains the details of every model evaluated in the boxplot with their label.

\begin{table}[ht]
	\centering
	\begin{tabular}{ |l|l|p{4cm}|p{4cm}| }
	 \hline
	  Project & Boxplot label & Code repository & Pretrained model \\
	 \hline
	 \hline
		\makecell[l]{Open-Unmix \\ \textcite{umx}} & umx & \url{https://github.com/sigsep/open-unmix-pytorch} & \url{https://zenodo.org/record/3370489} (UMX-HQ) \\
	 \hline
		\makecell[l]{CrossNet-Open-Unmix \\ \textcite{xumx}} & xumx & \url{https://github.com/sony/ai-research-code/tree/master/x-umx} & \url{https://nnabla.org/pretrained-models/ai-research-code/x-umx/x-umx.h5} (X-UMX) \\
	 \hline
		\makecell[l]{xumx-sliCQ \\ (this paper)} & sliCQ & \url{https://github.com/sevagh/xumx-sliCQ} & \url{https://github.com/sevagh/xumx-sliCQ/tree/main/pretrained-model} \\
	 \hline
\end{tabular}
	\caption{Evaluated pretrained models in the BSS boxplot}
	\label{table:bsseval}
\end{table}

\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth]{./images-bss/boxplot_full.png}
	\caption{Boxplot of full MUSDB18-HQ test set evaluation of Open-Unmix vs. CrossNet-Open-Unmix vs. xumx-sliCQ}
	\label{fig:bssboxplot}
\end{figure}

\subsection{Inference performance analysis}

\subsection{ISMIR 2021 Music Demixing Challenge}

\ichfeedback{i know this shouldn't be a core part of the thesis, but it's still fun to describe?}

\end{document}
