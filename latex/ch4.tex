\documentclass[report.tex]{subfiles}
\begin{document}

\section{Experiment}
\label{sec:experiment}

This section contains the results of the experiments described in section \ref{sec:methodology}.

The hardware and software specifications of the computer which produced the results in this section are as follows:
\begin{tight_enumerate}
	\item
		Motherboard: Gigabyte Aorus X570 Elite Wifi
	\item
		CPU: AMD Ryzen 5950X
	\item
		Memory: 64GB DDR4
	\item
		Storage: 1TB ADATA SX8200PNP NVMe
	\item
		GPUs: NVIDIA RTX 3080 Ti (12GB VRAM) and NVIDIA RTX 2070 Super (8GB VRAM)
	\item
		OS: Fedora 34 Workstation Edition, 64-bit
	\item
		Linux kernel version: 5.133.10-200
	\item
		NVIDIA driver version: 470.63.01
	\item
		NVIDIA CUDA toolkit version: 11.4
\end{tight_enumerate}

The Python environments used were designed to be reproducible with pip requirements.txt files or Conda environment files bundled with the source code:

\begin{tight_enumerate}
	\item
		Pip file for oracles, trained model evaluations, boxplot creation, and performance benchmarks:\\
		\url{https://gitlab.com/sevagh/xumx_slicq_extra/-/blob/main/mss_evaluation/mss-oracle-experiments/requirements-cupy.txt}
	\item
		Conda environment file for the NSGT/sliCQT PyTorch implementation:\\
		\url{https://github.com/sevagh/nsgt/blob/main/conda-env.yml}
	\item
		Conda environment file for the xumx-sliCQ neural network:\\
		\href{https://github.com/sevagh/xumx-sliCQ/blob/main/scripts/environment-gpu-linux-cuda11.yml}{https://github.com/sevagh/xumx-sliCQ/blob/main/scripts/environment-gpu-linux-cuda11.yml}
\end{tight_enumerate}

The repositories associated with this thesis are as follows:
\begin{tight_enumerate}
	\item
		xumx-sliCQ neural network:\\
		\url{https://github.com/sevagh/xumx-sliCQ}
	\item
		NSGT/sliCQT PyTorch copy:\\
		\url{https://github.com/sevagh/nsgt}
	\item
		museval (BSS metrics evaluation) CuPy copy:\\
		\url{https://github.com/sevagh/sigsep-mus-eval}
	\item
		LaTeX files and scripts for generating this thesis, including all plots and results:\\
		\url{https://gitlab.com/sevagh/xumx_slicq_extra}
	\item
		Submissions made to the ISMIR 2021 Music Demixing Challenge:\\
		\url{https://gitlab.aicrowd.com/sevagh/music-demixing-challenge-starter-kit}
\end{tight_enumerate}

The author of this thesis takes code availability and reproducibility seriously. Feel free to e-mail me\footnote{\href{mailto:sevag.hanssian@mail.mcgill.ca}{sevag.hanssian@mail.mcgill.ca}, \href{mailto:sevagh+thesis@pm.me}{sevagh+thesis@pm.me}} if you encounter any errors, discrepancies, or difficulties with reproducing any of the results.

\subsection{Benchmarks for GPU accelerations}

In section \ref{sec:torchslicq}, it was described that the sliCQT Python library uses the CPU-based NumPy library, and that it was necessary to port the code to the GPU-enabled PyTorch deep learning framework to allow it to run faster and directly on the GPU in the deep neural network of Open-Unmix.

In section \ref{sec:fasterbsscupy}, it was described that the BSS eval step was the slowest part of evaluating oracle performance, which is the important step in the sliCQT parameter selection. Replacing the CPU-based NumPy and SciPy libraries with the GPU-enabled CuPy library for math operations would speed up the oracle evaluations and allow the sliCQT parameter search script to run more efficiently.

The following sections show benchmark results to demonstrate the speedup of the sliCQT and BSS eval libraries achieved from their respective GPU ports.

\subsubsection{Faster NSGT/sliCQT with PyTorch}

The first benchmark script is for the PyTorch implementation of the NSGT/sliCQT library from section \ref{sec:torchslicq}. My copy of the library contains the PyTorch implementation and the benchmark scripts.\footnote{\url{https://github.com/sevagh/nsgt}, \url{https://github.com/sevagh/nsgt/blob/main/examples/benchmark.py}, \url{https://github.com/sevagh/nsgt/blob/main/examples/run_bench.sh}} The benchmark performs the forward and backward sliCQT using the Bark scale with 50 bins between 20--22,050 Hz. The sliCQT is taken on a 3:54 minute mixed song from the MUSDB18-HQ dataset, ``Zeno - Signs.'' The sliCQT parameters were chosen so that the transform of the song occupied a maximum of 7.2 GB of memory and could fit on the device with the least memory, the NVIDIA 2070 Super. The computation time was measured and averaged across 100 iterations. The cost of the memory transfer of the song to the GPU was not included in the measurement. Tables \ref{table:nsgttorchresultsmatrix} and \ref{table:nsgttorchresultsragged} show the benchmark results for the matrix and ragged sliCQT respectively.

\begin{table}[ht]
	\centering
	\caption{Execution times for the matrix form of the forward + backward sliCQT}
	\label{table:nsgttorchresultsmatrix}
	\begin{tabular}{ |l|l|l|l| }
	 \hline
		NSGT library & Device & Time (s) \\
	 \hline
	 \hline
		Original & CPU, multithreaded & 60.56  \\
	 \hline
		Original & CPU, single-threaded & 9.50  \\
	 \hline
		PyTorch & CPU & 3.10  \\
	 \hline
		PyTorch & GPU (2070 Super) & 2.62 \\
	 \hline
		PyTorch & GPU (3080 Ti) &  2.40 \\
	 \hline
\end{tabular}
\end{table}

\begin{table}[ht]
	\centering
	\caption{Execution times for the ragged form of the forward + backward sliCQT}
	\label{table:nsgttorchresultsragged}
	\begin{tabular}{ |l|l|l|l| }
	 \hline
		NSGT library & Device & Time (s) \\
	 \hline
	 \hline
		Original & CPU, multithreaded & 51.95  \\
	 \hline
		Original & CPU, single-threaded & 8.72  \\
	 \hline
		PyTorch & GPU (2070 Super) & 2.52 \\
	 \hline
		PyTorch & GPU (3080 Ti) &  2.38 \\
	 \hline
		PyTorch & CPU & 1.85  \\
	 \hline
\end{tabular}
\end{table}

The execution time of the transform improved with PyTorch. The GPUs have an advantage over the CPU in the matrix form of the transform, but not in the ragged form. This can be explained by the fact that the ragged transform is a list of tensors. To perform operations on the ragged transform requires looping over the list which negates some of the benefits of GPU parallelism. Even though the GPU is not faster than the CPU for the tested parameters of ragged sliCQT, having the transform on the GPU allows us to use the sliCQT inside a PyTorch neural network. The original library has a multithreaded option which performs worse than the default single-threaded behavior, but the PyTorch CPU performance leapfrogs both.

\subsubsection{Faster BSS metrics with CuPy}

The second benchmark script is for the GPU-accelerated BSS metrics computation using the CuPy library from section \ref{sec:fasterbsscupy}. Recall that the copy of the library\footnote{\url{https://github.com/sevagh/sigsep-mus-eval}} contains the modifications made for this thesis. For the 14 validation tracks of MUSDB18-HQ, the benchmark script\footnote{\url{https://gitlab.com/sevagh/xumx_slicq_extra/-/blob/main/mss_evaluation/mss-oracle-experiments/oracle_eval/benchmark_cupy_eval.py}}  creates a random estimate (using \Verb#numpy.randn# to create an audio signal) and computes the BSS metrics. It measures the time for each BSS metric computation, summed across 14 tracks and repeated for 10 iterations. The final time is the total time for all 14 tracks, divided by 10 to account for the iterations. Three copies of the script were run; one with the argument \Verb#--disable-cupy# to use the CPU code with SciPy and NumPy functions on a Ryzen 5950X with 64GB RAM, one with the argument \Verb#--cuda-device=0# to use the NVIDIA RTX 3080 Ti GPU, and one with the argument \Verb#--cuda-device=1# to use the NVIDIA RTX 2070 Super GPU.

The results were that the regular BSS metrics evaluation on the CPU took 1,485.77 seconds, compared to the CuPy GPU-accelerated code which took 585.33 seconds with the 3080 Ti and 738.39 seconds with the weaker 2070 Super. The speedup from CuPy is \textasciitilde 2-2.5x over the Ryzen 5950X CPU. This is a significant reduction that can aid in future large-scale source separation evaluation campaigns like SiSec \parencite{sisec2016, sisec2018}.

\newpagefill

\subsection{Best sliCQT parameters with MPI oracle}

As described in section \ref{sec:mpiparam}, a random parameter search was undertaken to choose the parameters of the sliCQT. The parameter search script\footnote{\url{https://github.com/sevagh/xumx-sliCQ/blob/main/scripts/slicq_explore.py}, \url{https://github.com/sevagh/xumx-sliCQ/blob/main/docs/slicq_params.md}} computes the median SDR score of the MPI oracle across all four targets and the 14 validation tracks of MUSDB18-HQ. The script ran for 60 iterations using random combinations of sliCQT parameters chosen from the ranges in section \ref{sec:mpiparam}.

For demonstration purposes, the inverse SDR score ($-1.0*\text{SDR}$) was maximized in a second search, to find sliCQT parameters with poor performance.

The best-performing sliCQT parameters chosen by the script used the following parameters: Bark scale, 262 bins, 32.9--22,050 Hz. These parameters were used in the final neural network, xumx-sliCQ. The worst-performing sliCQT parameters chosen by the inverse SDR maximization used the following parameters: Constant-Q (logarithmic) scale, 142 bins, 129.7--22,050 Hz. Figure \ref{fig:bipolarslicqs} shows the magnitude spectrograms of the good and bad sliCQT.

\begin{figure}[ht]
	\centering
	\subfloat[Good sliCQT -- Bark, 262 bins, 32.9--22,050 Hz]{\includegraphics[width=0.675\textwidth]{./images-gspi/slicqt_good.png}}\\
	\subfloat[Bad sliCQT -- Constant-Q/log, 142 bins, 129.7--22,050 Hz]{\includegraphics[width=0.675\textwidth]{./images-gspi/slicqt_bad.png}}
	\caption{sliCQTs from the MPI oracle hyperparameter search}
	\label{fig:bipolarslicqs}
\end{figure}

The full oracle evaluation on both of these sliCQT parameters are shown in the boxplot in Figure \ref{fig:oraclebssboxplot}, alongside different STFT window sizes. The bad sliCQT starts at a high frequency, 129.7 Hz, which is near the maximum of the 10--130 Hz range. From the spectrogram, we can see that the low frequency bins are very diffuse, or blurry. From the boxplot, we can see that the targets which are expected to be more pitched or tonal (vocals, other) perform similar with both the good and bad sliCQT, but the drums and bass are drastically worse for the bad sliCQT.

\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth]{./images-bss/oracle_boxplot.pdf}
	\caption{Boxplot for oracle mask evaluations}
	\label{fig:oraclebssboxplot}
\end{figure}

\subsubsection{sliCQT dimensionality analysis}

The slice length and transition length for the 262-bin Bark scale sliCQT with frequency limits of 32.9--22,050 Hz are automatically chosen to be 18,060 and 4,514 samples respectively.

The input data to xumx-sliCQ was split into to sequences of a one second duration. The slice length of the chosen scale results in one second of audio containing nine slices. Each slice consists of a number of time coefficients that varies with the frequency bin. The ragged transform contains 70 buckets of frequency bins grouped by their time resolution. Tables \ref{table:slicqdim1} and \ref{table:slicqdim2} show each bucket in the ragged transform with its original 3D shape ($\text{slice} \times \text{frequency} \times \text{time}$), and the flattened and overlap-added 2D shapes ($\text{time} \times \text{frequency}$).

Note that the channel dimension is omitted from the table. There is one spectrogram for each channel of audio, resulting in an additional $(, 2)$ dimension added to the sliCQT shape from the two channels of the stereo training data. The flattened shape is a result of concatenating the $\text{slice} \times \text{time}$ blocks together; e.g., to flatten $9 \times 10$ results in $90$. The overlap-add considers a $\sfrac{\text{time}}{2}$ overlap between each adjacent slice of size.

It is instructive to compare the dimensionality of the chosen sliCQT parameters to the matrix form of the sliCQT, and to the STFT with a window size of 4,096 and an overlap of 1,024.

The matrix form of the same sliCQT results in a 3D $\text{slice} \times \text{frequency} \times \text{time}$ shape of $9 \times 263 \times 292$, representing the same nine slices for one second of audio as the ragged transform, and 263 frequency bins, which includes the 0--32.9 Hz bin added to the 262 we specified between 32.9--22,050 Hz. The time coefficients are of length 292, which as shown in Table \ref{table:slicqdim2} is the maximum time resolution of the highest frequency bin. The other frequency bins have some operations performed including zero-padding to fit the same dimension. The 2D $\text{frequency} \times \text{time}$ shapes are $263 \times 1{,}022$ for the overlap-added spectrogram and $263 \times 1{,}752$ for the flattened spectrogram.

The STFT with a window of 4,096 samples and overlap of 1,024 samples results in a 2D $\text{frequency} \times \text{time}$ transform of shape $2{,}049 \times 40$, where 2,049 is the number of non-redundant output frequencies of the STFT, computed by $\sfrac{4{,}096}{2} + 1$, and 40 is the number of temporal frames computed from the signal length (or 44,100 samples for 1s of audio), window size, and overlap using equation \ref{equation:stftframes}:
\begin{align}
	\text{floor}\big(\frac{44{,}100-4{,}096}{1{,}024}\big) + 1 = 40\tag{37}\label{equation:stftframes}
\end{align}

\begin{table}[ht]
	\centering
	\caption{Dimensions of the forward ragged sliCQT, first 35 time buckets}
	\label{table:slicqdim1}
	\begin{tabular}{ |l|l|l|l|l| }
	 \hline
		Bucket & Frequency bins & 3D shape & 2D overlap-add shape & 2D flat shape \\
	 \hline
	 \hline
0 & 0 & (9, \ 1, \ 28) & (1, \ 98) & (1, \ 168) \\
\hline
1 & 1--86 & (9, \ 86, \ 16) & (86, \ 56) & (86, \ 96) \\
\hline
2 & 87--100 & (9, \ 14, \ 20) & (14, \ 70) & (14, \ 120) \\
\hline
3 & 101--111 & (9, \ 11, \ 24) & (11, \ 84) & (11, \ 144) \\
\hline
4 & 112--120 & (9, \ 9, \ 28) & (9, \ 98) & (9, \ 168) \\
\hline
5 & 121--128 & (9, \ 8, \ 32) & (8, \ 112) & (8, \ 192) \\
\hline
6 & 129--135 & (9, \ 7, \ 36) & (7, \ 126) & (7, \ 216) \\
\hline
7 & 136--141 & (9, \ 6, \ 40) & (6, \ 140) & (6, \ 240) \\
\hline
8 & 142--147 & (9, \ 6, \ 44) & (6, \ 154) & (6, \ 264) \\
\hline
9 & 148--152 & (9, \ 5, \ 48) & (5, \ 168) & (5, \ 288) \\
\hline
10 & 153--157 & (9, \ 5, \ 52) & (5, \ 182) & (5, \ 312) \\
\hline
11 & 158--161 & (9, \ 4, \ 56) & (4, \ 196) & (4, \ 336) \\
\hline
12 & 162--166 & (9, \ 5, \ 60) & (5, \ 210) & (5, \ 360) \\
\hline
13 & 167--169 & (9, \ 3, \ 64) & (3, \ 224) & (3, \ 384) \\
\hline
14 & 170--173 & (9, \ 4, \ 68) & (4, \ 238) & (4, \ 408) \\
\hline
15 & 174--177 & (9, \ 4, \ 72) & (4, \ 252) & (4, \ 432) \\
\hline
16 & 178--180 & (9, \ 3, \ 76) & (3, \ 266) & (3, \ 456) \\
\hline
17 & 181--183 & (9, \ 3, \ 80) & (3, \ 280) & (3, \ 480) \\
\hline
18 & 184--186 & (9, \ 3, \ 84) & (3, \ 294) & (3, \ 504) \\
\hline
19 & 187--189 & (9, \ 3, \ 88) & (3, \ 308) & (3, \ 528) \\
\hline
20 & 190--191 & (9, \ 2, \ 92) & (2, \ 322) & (2, \ 552) \\
\hline
21 & 192--194 & (9, \ 3, \ 96) & (3, \ 336) & (3, \ 576) \\
\hline
22 & 195--196 & (9, \ 2, \ 100) & (2, \ 350) & (2, \ 600) \\
\hline
23 & 197--199 & (9, \ 3, \ 104) & (3, \ 364) & (3, \ 624) \\
\hline
24 & 200--201 & (9, \ 2, \ 108) & (2, \ 378) & (2, \ 648) \\
\hline
25 & 202--203 & (9, \ 2, \ 112) & (2, \ 392) & (2, \ 672) \\
\hline
26 & 204--205 & (9, \ 2, \ 116) & (2, \ 406) & (2, \ 696) \\
\hline
27 & 206--207 & (9, \ 2, \ 120) & (2, \ 420) & (2, \ 720) \\
\hline
28 & 208--209 & (9, \ 2, \ 124) & (2, \ 434) & (2, \ 744) \\
\hline
29 & 210--211 & (9, \ 2, \ 128) & (2, \ 448) & (2, \ 768) \\
\hline
30 & 212--213 & (9, \ 2, \ 132) & (2, \ 462) & (2, \ 792) \\
\hline
31 & 214--215 & (9, \ 2, \ 136) & (2, \ 476) & (2, \ 816) \\
\hline
32 & 216--217 & (9, \ 2, \ 140) & (2, \ 490) & (2, \ 840) \\
\hline
33 & 218 & (9, \ 1, \ 144) & (1, \ 504) & (1, \ 864) \\
\hline
34 & 219--220 & (9, \ 2, \ 148) & (2, \ 518) & (2, \ 888) \\
\hline
\end{tabular}
\end{table}

\begin{table}[ht]
	\centering
	\caption{Dimensions of the forward ragged sliCQT, last 35 time buckets}
	\label{table:slicqdim2}
	\begin{tabular}{ |l|l|l|l|l| }
	 \hline
		Bucket & Frequency bins & 3D shape & 2D overlap-add shape & 2D flat shape \\
	 \hline
	 \hline
35 & 221--222 & (9, \ 2, \ 152) & (2, \ 532) & (2, \ 912) \\
\hline
36 & 223 & (9, \ 1, \ 156) & (1, \ 546) & (1, \ 936) \\
\hline
37 & 224--225 & (9, \ 2, \ 160) & (2, \ 560) & (2, \ 960) \\
\hline
38 & 226 & (9, \ 1, \ 164) & (1, \ 574) & (1, \ 984) \\
\hline
39 & 227--228 & (9, \ 2, \ 168) & (2, \ 588) & (2, \ 1,008) \\
\hline
40 & 229 & (9, \ 1, \ 172) & (1, \ 602) & (1, \ 1,032) \\
\hline
41 & 230--231 & (9, \ 2, \ 176) & (2, \ 616) & (2, \ 1,056) \\
\hline
42 & 232 & (9, \ 1, \ 180) & (1, \ 630) & (1, \ 1,080) \\
\hline
43 & 233 & (9, \ 1, \ 184) & (1, \ 644) & (1, \ 1,104) \\
\hline
44 & 234--235 & (9, \ 2, \ 188) & (2, \ 658) & (2, \ 1,128) \\
\hline
45 & 236 & (9, \ 1, \ 192) & (1, \ 672) & (1, \ 1,152) \\
\hline
46 & 237 & (9, \ 1, \ 196) & (1, \ 686) & (1, \ 1,176) \\
\hline
47 & 238 & (9, \ 1, \ 200) & (1, \ 700) & (1, \ 1,200) \\
\hline
48 & 239--240 & (9, \ 2, \ 204) & (2, \ 714) & (2, \ 1,224) \\
\hline
49 & 241 & (9, \ 1, \ 208) & (1, \ 728) & (1, \ 1,248) \\
\hline
50 & 242 & (9, \ 1, \ 212) & (1, \ 742) & (1, \ 1,272) \\
\hline
51 & 243 & (9, \ 1, \ 216) & (1, \ 756) & (1, \ 1,296) \\
\hline
52 & 244 & (9, \ 1, \ 220) & (1, \ 770) & (1, \ 1,320) \\
\hline
53 & 245 & (9, \ 1, \ 224) & (1, \ 784) & (1, \ 1,344) \\
\hline
54 & 246 & (9, \ 1, \ 228) & (1, \ 798) & (1, \ 1,368) \\
\hline
55 & 247--248 & (9, \ 2, \ 232) & (2, \ 812) & (2, \ 1,392) \\
\hline
56 & 249 & (9, \ 1, \ 236) & (1, \ 826) & (1, \ 1,416) \\
\hline
57 & 250 & (9, \ 1, \ 240) & (1, \ 840) & (1, \ 1,440) \\
\hline
58 & 251 & (9, \ 1, \ 244) & (1, \ 854) & (1, \ 1,464) \\
\hline
59 & 252 & (9, \ 1, \ 248) & (1, \ 868) & (1, \ 1,488) \\
\hline
60 & 253 & (9, \ 1, \ 252) & (1, \ 882) & (1, \ 1,512) \\
\hline
61 & 254 & (9, \ 1, \ 256) & (1, \ 896) & (1, \ 1,536) \\
\hline
62 & 255 & (9, \ 1, \ 264) & (1, \ 924) & (1, \ 1,584) \\
\hline
63 & 256 & (9, \ 1, \ 268) & (1, \ 938) & (1, \ 1,608) \\
\hline
64 & 257 & (9, \ 1, \ 272) & (1, \ 952) & (1, \ 1,632) \\
\hline
65 & 258 & (9, \ 1, \ 276) & (1, \ 966) & (1, \ 1,656) \\
\hline
66 & 259 & (9, \ 1, \ 280) & (1, \ 980) & (1, \ 1,680) \\
\hline
67 & 260 & (9, \ 1, \ 284) & (1, \ 994) & (1, \ 1,704) \\
\hline
68 & 261 & (9, \ 1, \ 288) & (1, \ 1,008) & (1, \ 1,728) \\
\hline
69 & 262 & (9, \ 1, \ 292) & (1, \ 1,022) & (1, \ 1,752) \\
\hline
\end{tabular}
\end{table}

\newpagefill

\subsection{xumx-sliCQ neural network}

\subsubsection{Learning parameters and training curves}

The learning hyperparameters of xumx-sliCQ were mostly kept the same to Open-Unmix and CrossNet-Open-Unmix. The training uses an Adam optimizer which runs for 1,000 iterations (or epochs), with a learning rate of 0.001 and a weight decay of 0.00001. There is also an adaptive learning rate scheduler with a decay patience of 80 and a decay gamma of 0.3. A difference between the learning hyperparameters of X-UMX and UMX is that the network trains for the full 1,000 epochs without any early stopping, which was also incorporated in xumx-sliCQ.

Recall from section \ref{sec:xumxinc} that X-UMX includes the cross-domain loss (CL), with a mixing coefficient between the magnitude spectrogram loss and the time-domain SDR loss. The mixing coefficient in X-UMX is 10.0, but in xumx-sliCQ it is set to 0.1 to reflect the observed order of magnitude difference in the MSE loss of the STFT and the sliCQT. xumx-sliCQ reports 6,669,912 trainable parameters in total from the torchinfo\footnote{\url{https://github.com/TylerYep/torchinfo}} package. The training curves can be seen in Figure \ref{fig:networkloss}, visualized using Tensorboard,\footnote{\url{https://www.tensorflow.org/tensorboard/}} a training visualization tool.

\begin{figure}[ht]
	\centering
	\subfloat[Train loss]{\includegraphics[width=\textwidth]{./images-neural/train_loss.png}}\\
	\subfloat[Validation loss]{\includegraphics[width=\textwidth]{./images-neural/valid_loss.png}}
	\caption{Tensorboard loss curves for xumx-sliCQ, 1,000 epochs}
	\label{fig:networkloss}
\end{figure}

\newpagefill

\subsubsection{Music demixing results}
\label{sec:demixresults}

The BSSv4 scores for the demixing results generated from the evaluation script\footnote{\url{https://gitlab.com/sevagh/xumx_slicq_extra/-/blob/main/mss_evaluation/mss-oracle-experiments/oracle_eval/trained_models.py}} were computed on the test set of the MUSDB18-HQ \parencite{musdb18hq} dataset, and are shown in Figure \ref{fig:bssboxplot}. Table \ref{table:bsseval} contains the details of every model evaluated in the boxplot with their label, and the median SDR across the four targets and 50 test tracks. ``-WEM'' denotes ``Wiener-expectation-maximization,'' the post-processing iterative refinement step of the four targets.

\begin{table}[ht]
	\centering
	\caption{Evaluated pretrained models in the BSS boxplot}
	\label{table:bsseval}
	\begin{tabular}{ |p{2.5cm}|l|l|p{3.5cm}|p{3.5cm}| }
	 \hline
		Project & Legend & SDR & Code repository & Pretrained model \\
	 \hline
	 \hline
		CrossNet-Open-Unmix & xumx & 5.54 & \url{https://github.com/sony/ai-research-code/tree/master/x-umx} & \url{https://nnabla.org/pretrained-models/ai-research-code/x-umx/x-umx.h5} \\
	 \hline
		Open-Unmix & umx & 4.64 & \url{https://github.com/sigsep/open-unmix-pytorch} & \url{https://zenodo.org/record/3370489} \\
	 \hline
		\makecell[l]{xumx-sliCQ \\ sliCQT-WEM} & slicq-wslicq & 3.71 & \url{https://github.com/sevagh/xumx-sliCQ} & \url{https://github.com/sevagh/xumx-sliCQ/tree/main/pretrained-model} \\
	 \hline
		\makecell[l]{xumx-sliCQ \\ STFT-WEM} & slicq-wstft & 3.60 & \url{https://github.com/sevagh/xumx-sliCQ} & \url{https://github.com/sevagh/xumx-sliCQ/tree/main/pretrained-model} \\
	 \hline
\end{tabular}
\end{table}

We discussed in section \ref{sec:replacestft} that after getting the initial estimate with the xumx-sliCQ neural network, there is a post-processing Wiener expectation maximization step that could be done with the sliCQT or the STFT. Both configurations were evaluated and shown in the boxplot.

Note that the default number of iterations for the Wiener-EM step is one, in UMX, X-UMX, and xumx-sliCQ. Anything above one iteration had worse demixing results, and was computationally slower as well. This is shown in Code Listing \ref{lst:wienerem}, where five different configurations of xumx-sliCQ's post-processing Wiener-EM were tested on a single track, ``Al James - Schoolboy Facination.'' The evaluated configurations were:
\begin{tight_enumerate}
	\item
		1 + 2 iterations of STFT-Wiener-EM
	\item
		1 + 2 iterations of ragged sliCQ-Wiener-EM
	\item
		1 iteration of zero-padded matrix sliCQ-Wiener-EM
\end{tight_enumerate}

\begin{listing}[h]
  \centering
\begin{minted}[numbersep=\mintednumbersep,linenos,mathescape=true,breaklines,frame=single,escapeinside=||,fontsize=\scriptsize]{text}
1 iteration of STFT-Wiener-EM:
    vocals          ==> SDR:   2.727  SIR:   7.992  ISR:   4.126  SAR:   2.082
    drums           ==> SDR:   2.702  SIR:   1.920  ISR:   5.649  SAR:   1.765
    bass            ==> SDR:   4.082  SIR:  10.806  ISR:   1.770  SAR:   2.128
    other           ==> SDR:  -0.939  SIR:  -3.560  ISR:  11.802  SAR:   3.516

    time: 3m41.839s

1 iteration of ragged sliCQ-Wiener-EM:
    vocals          ==> SDR:   2.754  SIR:   7.907  ISR:   4.166  SAR:   2.034
    drums           ==> SDR:   2.885  SIR:   1.511  ISR:   5.872  SAR:   1.649
    bass            ==> SDR:   4.134  SIR:  11.515  ISR:   1.349  SAR:   2.020
    other           ==> SDR:  -0.891  SIR:  -3.382  ISR:  12.241  SAR:   3.458

    time: 7m59.104s

1 iteration of zero-padded matrix sliCQ-Wiener-EM:
    vocals          ==> SDR:   2.753  SIR:   7.953  ISR:   4.158  SAR:   2.024
    drums           ==> SDR:   2.864  SIR:   1.677  ISR:   5.835  SAR:   1.657
    bass            ==> SDR:   4.140  SIR:  11.599  ISR:   1.350  SAR:   2.016
    other           ==> SDR:  -0.893  SIR:  -3.391  ISR:  12.189  SAR:   3.448

    time: 4m28.061s

2 iterations of STFT-Wiener-EM:
    vocals          ==> SDR:   2.368  SIR:   8.594  ISR:   4.081  SAR:   1.094
    drums           ==> SDR:   2.669  SIR:   2.600  ISR:   6.071  SAR:   1.466
    bass            ==> SDR:   3.892  SIR:  11.786  ISR:   1.576  SAR:   1.796
    other           ==> SDR:  -1.620  SIR:  -3.501  ISR:  12.949  SAR:   2.977

    time: 4m5.906s

2 iterations of ragged sliCQ-Wiener-EM:
    vocals          ==> SDR:   2.481  SIR:   8.152  ISR:   4.101  SAR:   1.173
    drums           ==> SDR:   2.832  SIR:   1.770  ISR:   6.270  SAR:   1.372
    bass            ==> SDR:   3.957  SIR:  12.244  ISR:   1.516  SAR:   1.809
    other           ==> SDR:  -1.505  SIR:  -3.357  ISR:  13.263  SAR:   3.029

    time: 12m55.510s
\end{minted}
  \caption{BSS results of various configurations of Wiener-EM post-processing}
  \label{lst:wienerem}
\end{listing}

To briefly discuss these results, the zero-padded matrix form of the sliCQ-Wiener-EM was significantly faster than looping over the ragged list of matrices, with a slight difference in BSS metrics from the ragged form. The zero-padded sliCQ-Wiener-EM is the chosen implementation in the final model, with an option to also use the STFT-Wiener-EM. Both types of Wiener-EM with the sliCQ beat the STFT. Also, in both cases, two iterations were considerably worse than one iteration. The computation time of the inference step will be discussed in more detail in the next section \ref{sec:inferenceperf} to discuss the tradeoff between the STFT and sliCQ Wiener-EM.

To maximize result reproducibility, all the pretrained models and code were downloaded from the public hosted locations shown in Table \ref{table:bsseval} and stored in a separate public repository to generate the results.\footnote{\url{https://gitlab.com/sevagh/xumx_slicq_extra/-/tree/main/mss_evaluation}}

\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth]{./images-bss/boxplot_full.pdf}
	\caption{Boxplot of UMX, X-UMX, and xumx-sliCQ alongside the oracles}
	\label{fig:bssboxplot}
\end{figure}

\newpagefill

\subsubsection{Model size and inference performance comparison}
\label{sec:inferenceperf}

The pretrained UMX-HQ model\footnote{\url{https://zenodo.org/record/3370489}} was one of the three compared neural networks as shown in Table \ref{table:bsseval} in section \ref{sec:demixresults}. The weights are for a PyTorch model, and it was only trained on MUSDB18-HQ. The size on disk of the model weights for the four targets combined is 137 MB.

The pretrained X-UMX model\footnote{\url{https://nnabla.org/pretrained-models/ai-research-code/x-umx/x-umx.h5}} is for the NNabla deep learning framework. The file containing trained weights for the combined four targets is 136 MB, almost the same as the size of the UMX PyTorch weights.

The pretrained xumx-sliCQ model\footnote{\url{https://github.com/sevagh/xumx-sliCQ/tree/main/pretrained-model}} is 28 MB, making xumx-sliCQ the smallest network from the comparison.

To report the inference performance, only the CPU was used. The CPU is a more universal device for performing inference, as almost every computing device (desktop, laptop, server, smartphone, etc.) has a CPU while not all have deep-learning capable GPUs \parencite{deepcpuinf, deepcpuinf2}. The time to perform the separation of a mixed song into four stems (including the Wiener-EM step) was averaged across the first 10 songs of the 50-song test set of MUSDB18-HQ. The music demixing result generation script from the previous section \ref{sec:demixresults} was simply adapted to add timing measurements. Note that X-UMX was omitted from the comparison, since it runs on NNabla, a different deep learning framework than PyTorch.

Table \ref{table:infperf} shows the measured times. For xumx-sliCQ, both the sliCQT-Wiener-EM and STFT-Wiener-EM post-processing steps were measured.

\begin{table}[ht]
	\centering
	\caption{Execution times for the inference of the models}
	\label{table:infperf}
	\begin{tabular}{ |l|l|l| }
	 \hline
		Model & Device & Time (s) \\
	 \hline
	 \hline
		UMX & CPU & 27.26  \\
	 \hline
		xumx-sliCQ, STFT-WEM & CPU & 55.59  \\
	 \hline
		xumx-sliCQ, sliCQT-WEM & CPU & 104.54  \\
	 \hline
\end{tabular}
\end{table}

xumx-sliCQ is slower in its inference performance than UMX. Overall, xumx-sliCQ is smaller on disk, which is an advantage over UMX, but it executes \textasciitilde2x slower than UMX with the STFT-Wiener-EM step while producing lower BSS metrics in the music demixing task. xumx-sliCQ with the sliCQT-Wiener-EM step is \textasciitilde2x slower than with the STFT-Wiener-EM step for a small \textasciitilde0.1 dB boost in the median SDR score.

\end{document}
