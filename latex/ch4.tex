\documentclass[report.tex]{subfiles}
\begin{document}

\section{Experiment}
\label{sec:experiment}

This section contains the results of the experiments described in the previous section \ref{sec:methodology}. Refer to appendix \ref{appendix:computerspec} for the hardware and software specifications of the computer on which the experiments and results in this section were generated from.

\subsection{PyTorch port of the sliCQT}
\label{sec:gpuexperimentpytorch}

In section \ref{sec:torchslicq}, it was described how the CPU-based NumPy implementation of the reference sliCQT Python library was ported to PyTorch to enable its computation on the GPU for use in deep neural networks.

The benchmark script for the PyTorch implementation of the sliCQT\footnote{\url{https://github.com/sevagh/nsgt}, \url{https://github.com/sevagh/nsgt/blob/main/examples/benchmark.py}, \url{https://github.com/sevagh/nsgt/blob/main/examples/run_bench.sh}} performs the forward and backward sliCQT using the Bark scale with 50 bins between 20--22,050 Hz. The sliCQT is taken on a single 3:54 minute song from the MUSDB18-HQ dataset, ``Zeno - Signs.'' The sliCQT parameters were chosen so that the transform of the song occupied a maximum of 7.2 GB of memory and could fit on the device with the least memory, the NVIDIA 2070 Super GPU. The computation time was repeated for 100 iterations and averaged. The cost of the memory transfer of the song to the GPU was not included in the measurement. Table \ref{table:nsgttorchresultsragged} shows the benchmark results.

\begin{table}[ht]
	\centering
	\caption{Execution times for the forward + backward ragged sliCQT}
	\label{table:nsgttorchresultsragged}
	\begin{tabular}{ |l|l|l|l| }
	 \hline
		NSGT library & Device & Time (s) \\
	 \hline
	 \hline
		Original & CPU, multithreaded & 51.95  \\
	 \hline
		Original & CPU, single-threaded & 8.72  \\
	 \hline
		PyTorch & GPU (NVIDIA 2070 Super) & 2.52 \\
	 \hline
		PyTorch & GPU (NVIDIA 3080 Ti) &  2.38 \\
	 \hline
		PyTorch & CPU & 1.85  \\
	 \hline
\end{tabular}
\end{table}

\subsection{CuPy port of BSS metrics}
\label{sec:gpuexperimentpytorch}

In section \ref{sec:fasterbsscupy}, the slowest functions of the BSS metrics library that used CPU-based NumPy and SciPy operations were ported to the GPU-equivalent CuPy functions to speed up their computation.

The benchmark script for the CuPy BSS metrics library\footnote{\url{https://github.com/sevagh/sigsep-mus-eval}, \url{https://gitlab.com/sevagh/xumx_slicq_extra/-/blob/main/mss_evaluation/mss-oracle-experiments/oracle_eval/benchmark_cupy_eval.py}} creates a random estimated waveform for the four targets of the 14 validation tracks of MUSDB18-HQ, and computes the BSS metrics. The computation time was repeated for 10 iterations and averaged. Three copies of the benchmark script were run; one with the argument \Verb#--disable-cupy# to use the CPU code with SciPy and NumPy functions on the AMD Ryzen 5950X CPU, one with the argument \Verb#--cuda-device=0# to use the NVIDIA 3080 Ti GPU, and one with the argument \Verb#--cuda-device=1# to use the NVIDIA RTX 2070 Super GPU.

The results were that the regular BSS metrics evaluation on the CPU took 1,485.77 seconds, compared to the CuPy GPU-accelerated code which took 585.33 seconds with the NVIDIA 3080 Ti GPU and 738.39 seconds with the weaker NVIDIA 2070 Super GPU. The results show that the expected speedup for BSS metrics evaluations from a GPU is \textasciitilde 2-2.5x over the CPU.

\subsection{Best sliCQT parameters with MPI oracle}
\label{sec:slicqparamresults}

In section \ref{sec:slicqparamsrch}, a random grid search was described to choose the parameters of the sliCQT to use in xumx-sliCQ.

The parameter search script\footnote{\url{https://github.com/sevagh/xumx-sliCQ/blob/v2021/scripts/slicq_explore.py}, \url{https://github.com/sevagh/xumx-sliCQ/blob/v2021/docs/slicq_params.md}} computes the median SDR score of the MPI oracle across all four targets and the 14 validation tracks of MUSDB18-HQ. The script ran for 60 iterations using random combinations of sliCQT parameters chosen from the ranges in Table \ref{table:slicqparams} in section \ref{sec:slicqparamsrch}.

The best-performing sliCQT parameters chosen by the script used the following parameters: Bark scale, 262 bins, 32.9--22,050 Hz. These parameters were used in the final neural network, xumx-sliCQ. Figure \ref{fig:bipolarslicqs} shows a visual comparison of the magnitude spectrograms of the best-performing sliCQT parameters alongside the STFT with the UMX default window size of 4,096 samples.

\begin{figure}[ht]
	\centering
	\subfloat[Best sliCQT from MPI oracle parameter search]{\includegraphics[width=0.675\textwidth]{./images-gspi/slicqt_good.png}}\\
	\subfloat[STFT with UMX defaults]{\includegraphics[width=0.675\textwidth]{./images-gspi/glock_stft_4096.png}}
	\caption{Magnitude spectrogram comparison; sliCQT vs. STFT}
	\label{fig:bipolarslicqs}
\end{figure}

The full MPI oracle evaluation of these sliCQT parameters are shown in the boxplot in Figure \ref{fig:oraclebssboxplot}, alongside different STFT window sizes. The MPI oracle was described in section \ref{sec:noisyphaseoracle} as the strategy used by UMX to use the phase of the mix and estimated magnitude of the source to compute the final estimated source waveform.

\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth]{./images-bss/oracle_boxplot.pdf}
	\caption{Boxplot for MPI oracle mask evaluations}
	\label{fig:oraclebssboxplot}
\end{figure}

The slice length and transition length for the 262-bin Bark scale sliCQT with frequency limits of 32.9--22,050 Hz are automatically chosen to be 18,060 and 4,514 samples respectively, using the automatic slice length picker described in section \ref{sec:improvelib}. The median SDR achieved by the chosen sliCQT parameters in the MPI oracle was 7.42 dB, beating the 6.23 dB achieved by the STFT with the UMX default window and overlap of 4,096 and 1,024 samples respectively.

\newpagefill

\subsection{xumx-sliCQ neural network}

This section will show the hyperparameters, training procedure, and final trained performance of the xumx-sliCQ neural network, whose design was described in section \ref{sec:neuralnet}.

\subsubsection{Hyperparameters in the training script}

This section will cover the details of the hyperparameters of the xumx-sliCQ training script. Table \ref{table:xumxslicqparams} contains a full list of all the hyperparameters, their default values, and their origin. The origins of the parameters are either copied from UMX, X-UMX, or sections from this thesis which describe new hyperparameters, or values of existing hyerparameters that are different from the default value used in UMX or X-UMX.

\begin{table}[ht]
	\centering
	\caption{Arguments for the xumx-sliCQ training script to define hyperparameters}
	\label{table:xumxslicqparams}
	\begin{tabular}{ |l|l|l| }
	 \hline
		Parameter & Default & Origin \\
	 \hline
	 \hline
		Dataset & MUSDB18-HQ & Copied from UMX \\
	 \hline
		Learning rate & 1e-3 & Copied from UMX \\
	 \hline
		Learning rate decay patience & 80 & Copied from UMX \\
	 \hline
		Learning rate decay gamma & 0.3 & Copied from UMX \\
	 \hline
		Weight decay & 1e-5 & Copied from UMX \\
	 \hline
	 	Seed & 42 & Copied from UMX \\
	 \hline
	 	Bandwidth & 16000 Hz & Copied from UMX \\
	 \hline
	 	Number of channels & 2 & Copied from UMX \\
	 \hline
	 	Number of workers for dataloader & 4 & Copied from UMX \\
	 \hline
		Epochs & 1,000 & Copied from X-UMX \\
	 \hline
		Patience & 1,000 & Copied from X-UMX \\
	 \hline
		Frequency scale & Bark & Sections \ref{sec:slicqparamsrch}, \ref{sec:slicqparamresults} \\
	 \hline
		Frequency bins & 262 & Sections \ref{sec:slicqparamsrch}, \ref{sec:slicqparamresults} \\
	 \hline
	 	Minimum frequency & 32.9 Hz & Sections \ref{sec:slicqparamsrch}, \ref{sec:slicqparamresults} \\
	 \hline
		Sequence duration & 1 s & Section \ref{sec:replacestft} \\
	 \hline
		Use Bi-LSTM instead of CDAE & False & Section \ref{sec:slicqarches}  \\
	 \hline
		Mixing coefficient & 0.1 & Section \ref{sec:xumxinc} \\
	 \hline
\end{tabular}
\end{table}

The optimizer used is the Adam optimizer, with an adaptive learning rate scheduler, unchanged from UMX.

\subsubsection{Network architecture and training}
\label{sec:networktraining}

In this section, we will describe the neural network architectures and training results for both the Bi-LSTM and CDAE architectures of xumx-sliCQ. We will use the torchinfo\footnote{\url{https://github.com/TylerYep/torchinfo}} package to get a count of the total trainable parameters of the neural network. We will show the loss curves of the training process with Tensorboard,\footnote{\url{https://www.tensorflow.org/tensorboard/}} a neural network training visualization tool.

For the Bi-LSTM configuration of xumx-sliCQ, there are 1,889,512 trainable parameters in total. The training time per epoch within the first 10 epochs was 53 minutes, which would result in a hypothetical total of 36 days to train the full 1000 epochs. We did not complete the training and could not evaluate this configuration, due to the very high duration per epoch; this decision will be discussed further in section \ref{sec:netdiscuss}.

For the CDAE configuration of xumx-sliCQ, there are 6,669,912 trainable parameters in total. The training time per epoch took 350 seconds, or almost 6 minutes, representing a total of 100 hours or 4 days of training. The total training curves for the full 1000 epochs can be seen in Figure \ref{fig:networkloss}. The lowest validation loss achieved was -0.449 at epoch 583.

\begin{figure}[ht]
	\centering
	\subfloat[Train loss]{\includegraphics[width=\textwidth]{./images-neural/train_loss.png}}\\
	\subfloat[Validation loss]{\includegraphics[width=\textwidth]{./images-neural/valid_loss.png}}
	\caption{Tensorboard loss curves for xumx-sliCQ, 1,000 epochs}
	\label{fig:networkloss}
\end{figure}

\subsubsection{Wiener-EM post-processing details}
\label{sec:wienerconfigs}

We previously discussed in section \ref{sec:postprocessing} that after getting the initial estimate with the xumx-sliCQ neural network, there is a post-processing Wiener-EM step that could be done with the sliCQT or the STFT. In this section, we will discuss the execution times and SDR scores of the different configurations of Wiener-EM post-processing.

Note that the default number of iterations for the Wiener-EM step is one, in UMX, X-UMX, and xumx-sliCQ. Anything above one iteration had worse demixing results, and was computationally slower as well. This is shown in Table \ref{table:wienerem}, where five different configurations of xumx-sliCQ's post-processing Wiener-EM were tested on the first test track of MUSDB18-HQ, ``Al James - Schoolboy Facination.''

\begin{table}[ht]
	\centering
	\caption{SDR of Wiener-EM post-processing with the STFT and sliCQT}
	\label{table:wienerem}
	\begin{tabular}{ |l|l|l|l| }
	 \hline
		Wiener-EM implementation & Iterations & Median SDR & Execution time (s) \\
	 \hline
	 \hline
		sliCQT, ragged & 1 & 2.221 & 479.104 \\
	 \hline
		sliCQT, zero-padded matrix & 1 & 2.216 & 268.061  \\
	 \hline
		STFT & 1 & 2.143 & 221.839  \\
	 \hline
		sliCQT, ragged & 2 & 1.941 & 775.51  \\
	 \hline
		STFT & 2 & 1.827 & 245.906  \\
	 \hline
\end{tabular}
\end{table}

\subsubsection{Music demixing results}
\label{sec:demixresults}

In this section, the music demixing results of the trained models UMX, X-UMX, and xumx-sliCQ will be compared.

The BSSv4 scores for the demixing results generated from the evaluation script\footnote{\url{https://gitlab.com/sevagh/xumx_slicq_extra/-/blob/main/mss_evaluation/mss-oracle-experiments/oracle_eval/trained_models.py}} were computed on the test set of the MUSDB18-HQ dataset, and are shown in Figure \ref{fig:bssboxplot}. Table \ref{table:bsseval} contains the details of every model evaluated in the boxplot with their label, and the median SDR across the four targets and 50 test tracks. The sliCQT-Wiener-EM implementation is the zero-padded matrix form described in sections \ref{sec:postprocessing} and \ref{sec:wienerconfigs}, preferred over the ragged sliCQT-Wiener-EM step due to its faster computation time. Wiener-EM will be abbreviated to WEM in the following tables.

To maximize result reproducibility, all pretrained models and code were downloaded from their public hosted locations shown in Table \ref{table:bsseval} and stored in a separate repository to generate the results.\footnote{\url{https://gitlab.com/sevagh/xumx_slicq_extra/-/tree/main/mss_evaluation}}

\begin{table}[ht]
	\centering
	\caption{Evaluated pretrained models in the BSS boxplot}
	\label{table:bsseval}
	\begin{tabular}{ |p{2.5cm}|l|l|p{3.5cm}|p{3.5cm}| }
	 \hline
		Project & Legend & SDR & Code repository & Pretrained model \\
	 \hline
	 \hline
		CrossNet-Open-Unmix & xumx & 5.54 & \url{https://github.com/sony/ai-research-code/tree/master/x-umx} & \url{https://nnabla.org/pretrained-models/ai-research-code/x-umx/x-umx.h5} \\
	 \hline
		Open-Unmix & umx & 4.64 & \url{https://github.com/sigsep/open-unmix-pytorch} & \url{https://zenodo.org/record/3370489} \\
	 \hline
		\makecell[l]{xumx-sliCQ \\ sliCQT-WEM} & slicq-wslicq & 3.71 & \url{https://github.com/sevagh/xumx-sliCQ} & \url{https://github.com/sevagh/xumx-sliCQ/tree/main/pretrained-model} \\
	 \hline
		\makecell[l]{xumx-sliCQ \\ STFT-WEM} & slicq-wstft & 3.6 & \url{https://github.com/sevagh/xumx-sliCQ} & \url{https://github.com/sevagh/xumx-sliCQ/tree/main/pretrained-model} \\
	 \hline
\end{tabular}
\end{table}

\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth]{./images-bss/boxplot_full.pdf}
	\caption{Boxplot of UMX, X-UMX, and xumx-sliCQ alongside the oracles}
	\label{fig:bssboxplot}
\end{figure}

\newpagefill

\subsubsection{Model size and inference performance comparison}
\label{sec:inferenceperf}

In this section, we will measure the size on disk and inference running times of the models.

The pretrained UMX-HQ model\footnote{\url{https://zenodo.org/record/3370489}} for the PyTorch deep learning framework has a size on disk of 137 MB for all four targets combined.

The pretrained X-UMX model\footnote{\url{https://nnabla.org/pretrained-models/ai-research-code/x-umx/x-umx.h5}} for the NNabla deep learning framework has a size on disk of 136 MB for the four combined targets, which is almost the same as the size of the UMX PyTorch weights.

The pretrained xumx-sliCQ model\footnote{\url{https://github.com/sevagh/xumx-sliCQ/tree/main/pretrained-model}} for the PyTorch deep learning framework has a size on disk of 28 MB, making xumx-sliCQ the smallest network from the comparison.

To report the inference performance, only the CPU was used. The CPU is a more universal device for performing inference, as almost every computing device (desktop, laptop, server, smartphone, etc.) has a CPU while not all have deep-learning capable GPUs \parencite{deepcpuinf, deepcpuinf2}.

The time to perform the separation of a mixed song into four stems (including the Wiener-EM step) was averaged across the first 10 songs of the 50-song test set of MUSDB18-HQ. Table \ref{table:infperf} shows the measured times. For xumx-sliCQ, both the STFT and sliCQT configurations of the post-processing Wiener-EM step were measured, denoted as STFT-WEM and sliCQT-WEM respectively.

\begin{table}[ht]
	\centering
	\caption{Execution times of CPU inference and model sizes}
	\label{table:infperf}
	\begin{tabular}{ |l|l|l| }
	 \hline
		Model & Size on disk & Time (s) \\
	 \hline
	 \hline
		UMX & 137 MB & 27.26  \\
	 \hline
		X-UMX & 136 MB & 528.19  \\
	 \hline
		xumx-sliCQ, STFT-WEM & 28 MB & 55.59  \\
	 \hline
		xumx-sliCQ, sliCQT-WEM & 28 MB & 104.54  \\
	 \hline
\end{tabular}
\end{table}

\end{document}
