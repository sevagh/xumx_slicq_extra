\documentclass[letter,12pt]{article}
\usepackage[left=4cm, right=2.5cm, top=2.5cm, bottom=2.5cm]{geometry}
\usepackage{todonotes}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}
\usepackage{setspace}
\renewcommand{\topfraction}{0.85}
\renewcommand{\textfraction}{0.1}
\renewcommand{\floatpagefraction}{0.75}
\usepackage[backend=biber,authordate,annotation,url=false]{biblatex-chicago}
\addbibresource{citations.bib}
\input{variables.tex}

\newenvironment{tight_enumerate}{
\begin{enumerate}
  \setlength{\itemsep}{0pt}
  \setlength{\parskip}{0pt}
}{\end{enumerate}}

\title{\ThesisTitle}
\author{Sevag Hanssian, sevag.hanssian@mail.mcgill.ca}

\begin{document}

\maketitle

\section{Introduction / Motivation}

Music source separation, or music demixing, is the task of decomposing or ``demixing'' a mixed recording of a song into its constituent sources, which are typically isolated instruments (e.g., drums, bass, vocals). Music demixing algorithms commonly operate on the time-frequency representation of the music signals, computed with the Short-Time Fourier Transform (STFT). Due to the time-frequency uncertainty principle (\cite{gabor1946}), the STFT of a signal cannot be maximally precise in both time and frequency, and the tradeoff of time-frequency resolution can significantly affect music demixing results (\cite{tftradeoff1}). In this thesis, the sliCQT (\cite{slicq}), an STFT-like transform with varying time-frequency resolution, is explored as a replacement for the STFT in a state-of-the-art deep learning model for music demixing, Open-Unmix (\cite{umx}).

The STFT is computed by applying the discrete Fourier Transform on overlapping, fixed-size windows of the input signal. \textcite{doerflerphd} suggests that from both auditory and musical motivations, musical signals should be analyzed with long windows in the low frequency regions to capture detailed harmonic information, and short windows in the high frequency regions to capture transients with sharp temporal localization. The sliCQ Transform, or sliCQT, is a realtime implementation of the Nonstationary Gabor Transform (\cite{balazs}), a time-frequency transform with a perfect inverse with windows that vary with time. An important application of the sliCQT is to implement the Constant-Q Transform (CQT) for music (\cite{jbrown}).

Machine learning models for music source separation have achieved recent success (\cite{sisec2018}), and the STFT is used by several of the top performers. \textcite{umx}'s Open-Unmix was released as a state-of-the-art baseline and reference implementation for music demixing based on the STFT and published as open-source software.\footnote{\url{https://github.com/sigsep/open-unmix-pytorch}} In this thesis, Open-Unmix will be adapted to use the sliCQT in place of the STFT, and the proposed model should demonstrate a viable starting point for music demixing with the sliCQT.

\section{Previous Work}

Computational source separation has a long history (\cite{musicsepgood}), originating from the task of separating clean speech from background noise. Speech algorithms could not be generalized easily to music, and techniques more specific to music source separation were developed as a result (\cite{musicseptechniques1}). Accordingly, musical source models arose which try to exploit the characteristics of the sources in the STFT domain, such as Kernel Additive Modeling or Nonnegative Matrix Factorization (\cite{musicsepgood}). More recently, data-driven models based on machine learning surpassed previous approaches (\cite{sisec2018}). Open-Unmix was created by \textcite{umx} as an open-source, reference implementation of a state-of-the-art deep neural network for music demixing that uses the STFT.

Manipulating time-frequency resolution is one possible strategy for improving music demixing with the STFT. \textcite{driedger} used multiple STFTs with different window sizes, \textcite{fitzgerald2} replaced the STFT with the CQT, and \textcite{wavelets} used a custom wavelet transform.

\section{Proposed Research / Methodology}

The adaptation of Open-Unmix to use the sliCQT depends on two preliminary tasks. First, the reference Python implementation of the sliCQT\footnote{\url{https://github.com/grrrr/nsgt}} needs to be modified to use a GPU-capable deep learning framework. Next, sliCQT parameters must be chosen that can surpass the STFT in music source separation. Finally, Open-Unmix will be adapted to replace the sliCQT with the STFT, and the music demixing results will be compared with the original pre-trained model according to the SiSec 2018 music demixing evaluation methodologies (\cite{sisec2018}).

\section{Contributions / Summary}

In music demixing approaches that use the STFT, choosing the appropriate time-frequency resolution plays an important role. In this thesis, the sliCQT with varying time-frequency resolution is explored as a replacement for the STFT in a state-of-the-art deep learning model for music demixing, Open-Unmix. The resulting neural network could successfully perform the task of music demixing with BSS scores that were competitive with the reference Open-Unmix, with a \textasciitilde$5 \times$ smaller network.

\vfill
\clearpage %force a page break

%\nocite{*}
\printbibheading[title={References},heading=bibnumbered]
\printbibliography[heading=none]

\vfill
\clearpage %force a page break

\end{document}
