\documentclass[letter,12pt]{article}
\usepackage[left=2cm, right=2cm, top=2cm, bottom=2cm]{geometry}
%\setlength{\parindent}{0pt}
%\usepackage[shortlabels]{enumitem}
%\usepackage{graphicx}
%\usepackage{amsmath}
%\usepackage{amssymb}
%\usepackage{verbatim}
%\usepackage{listings}
%\usepackage{minted}
%\usepackage{subfig}
\usepackage{todonotes}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}
\usepackage{setspace}
\renewcommand{\topfraction}{0.85}
\renewcommand{\textfraction}{0.1}
\renewcommand{\floatpagefraction}{0.75}
\usepackage[backend=biber,authordate,annotation,url=false]{biblatex-chicago}
\addbibresource{citations.bib}
\input{variables.tex}

\newenvironment{tight_enumerate}{
\begin{enumerate}
  \setlength{\itemsep}{0pt}
  \setlength{\parskip}{0pt}
}{\end{enumerate}}

\title{\ThesisTitle}
\author{Sevag Hanssian, sevag.hanssian@mail.mcgill.ca}

\begin{document}

\maketitle

\section{Introduction / Motivation}


The Short-Time Fourier Transform (STFT) is an important tool for the time-frequency analysis of acoustic signals. It is computed by applying the discrete Fourier Transform on overlapping, fixed-size windows of the input signal, and it is commonly used to represent music in computational musical algorithms. Despite its popularity, the STFT limited by a fixed and bounded time-frequency resolution, controlled by the window size. In the task of music source separation or demixing (\cite{musicsepgood}), a stereo or mono recording of a mixed song is decomposed or ``demixed'' into its constituent sources, which are typically isolated instruments (e.g. drums, bass, vocals). Machine learning models for music source separation with the STFT have achieved recent success (\cite{sisec2018}). However, choosing the appropriate time-frequency resolution for the STFT with the window size is a crucial step which can significantly affect demixing results (\cite{tftradeoff1}).

 \textcite{doerflerphd} suggests that from auditory and musical motivations, musical signals should be analyzed with long windows in the low frequency regions to capture detailed harmonic information, and short windows in the high frequency regions to capture transients with sharp temporal localization. The sliCQ Transform (\cite{invertiblecqt}), or sliCQT, is the realtime variant of the Nonstationary Gabor Transform (\cite{balazs}), an STFT-like transform with a perfect inverse where the windows are varied with time to adapt the time-frequency resolution to fit the desired analysis characteristics. An important application of the sliCQT is to implement the constant-Q transform (CQT) for music (\cite{jbrown}). In this thesis, the STFT is replaced with the sliCQT in Open-Unmix (\cite{umx}), a neural network for music demixing. The proposed model demonstrates a viable and flexible starting point for spectral demixing using the sliCQT.

\section{Previous Work}

Computational source separation has a long history (\cite{musicsepintro1}), originating from the task of blind source separation (BSS), used for speech denoising. In blind source separation, Independent Component Analysis (ICA) is an algorithm which exploits spatial information, but it can only be used when there are as many channels in the mixture (corresponding to differently placed microphones) as the number of sources (\cite{ica1}). ICA also depends on sources being independent and stationary (\cite{musicsepintro1}). According to \textcite{musicsepintro1}, music source separation violates these requirements by typically being recorded in mono or stereo, being dependent (e.g. singing voice and piano in the same key), and being nonstationary (each musical source varies meaningfully with time, unlike noise). As a result, music-specific approaches were devised, including spectral techniques based on the STFT like Kernel Additive Modeling (KAM) or Nonnegative Matrix Factorization (NMF) (\cite{musicsepgood}).

More recently, data-driven models based on deep learning surpassed previous approaches (\cite{sisec2018}). Open-Unmix was created by \textcite{umx} as an open-source, reference implementation of a state-of-the-art deep neural network for music demixing. Open-Unmix is based on STFT masking, and is intended to foster reproducible research by only using the open MUSDB18-HQ dataset for training data (\cite{musdb18hq}). Manipulating time-frequency resolution is one of many strategies for improving spectral music demixing. \textcite{driedger} used multiple STFTs with different window sizes. \textcite{fitzgerald2} replaced the STFT with the constant-Q transform. \textcite{plumbley2} used varying sizes of time and frequency filters applied to the STFT according to the constant-Q scale.

\section{Proposed Research / Methodology}

To support the use of the sliCQT inside deep learning networks, the reference Python implementation of the sliCQT\footnote{\url{https://github.com/grrrr/nsgt}} needs to be modified to add support for GPUs using a deep learning framework. Next, sliCQT parameters must be chosen that can surpass the STFT in music source separation. Spectrograms from the sliCQT will be shown alongside STFT spectrograms with different window sizes to demonstrate the improved visual clarity of tonal and transient components, and better detection of musical events.

Finally, Open-Unmix will be adapted to use the sliCQT in place of the STFT, potentially incorporating ideas from other neural networks for music source separation including convolutional architectures (\cite{plumbley2}). The network should be trained using only the open MUSDB18-HQ dataset (\cite{musdb18hq}), and music separation results will be compared with the pre-trained Open-Unmix model using the BSS evaluation metrics (\cite{bss, sisec2018}).

\section{Contributions / Summary}

In spectral music demixing approaches that use the STFT, choosing the appropriate time-frequency resolution with the window size plays an important role. In this thesis, the sliCQT with varying time-frequency resolution is explored as a replacement for the STFT in a deep learning model for music demixing, Open-Unmix. The resulting neural network could successfully perform the task of music demixing with BSS scores that were competitive with the reference Open-Unmix, with a \textasciitilde$5 \times$ smaller network. The proposed model was also submitted to the ISMIR 2021 Music Demixing Challenge,\footnote{\url{https://www.aicrowd.com/challenges/music-demixing-challenge-ismir-2021}}\textsuperscript{,}\footnote{\url{https://mdx-workshop.github.io/}} demonstrating that it could pass a verified third-party evaluation process. The sliCQT is a flexible transform, and future work should explore alternative parameter search strategies or neural network architectures to further improve demixing performance. 

\vfill
\clearpage %force a page break

%\nocite{*}
\printbibheading[title={References},heading=bibnumbered]
\printbibliography[heading=none]

\vfill
\clearpage %force a page break

\end{document}
