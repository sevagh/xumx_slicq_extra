\documentclass[usenames,dvipsnames]{beamer}
\usetheme{Boadilla}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{multimedia}
\usepackage{fancyvrb}
\usepackage{soul}
\usepackage{multicol}
\usepackage{optparams}
\usepackage{adjustbox}
\usepackage{tikz}
\usetikzlibrary{shapes,positioning}
\newcommand{\foo}{\hspace{-2.3pt}$\bullet$ \hspace{5pt}}
\usepackage{subfig}
\usepackage[
    backend=biber,
    natbib=true,
    style=numeric,
    sorting=none,
    style=verbose-ibid,
    maxcitenames=1, %remove this outside of toy presentations
]{biblatex}
\addbibresource{citations.bib}
\usepackage{pgfpages}
\usepackage{xcolor}
\definecolor{ao(english)}{rgb}{0.0, 0.5, 0.0}
\definecolor{burgundy}{rgb}{0.5, 0.0, 0.13}
%\setbeameroption{show notes}
%\setbeameroption{show notes on second screen=right}
\setbeameroption{hide notes}
\input{variables.tex}

\title{Music demixing with the sliCQ transform}
\author{Sevag Hanssian}
%\date{August 21, 2021}
\date{}
\setbeamertemplate{navigation symbols}{}

\AtEveryBibitem{%
  \clearfield{pages}%
  \clearfield{volume}%
  \clearfield{number}%
  \clearlist{journal}%
  \clearfield{booktitle}%
}

\renewbibmacro{in:}{}

\AtEveryCitekey{%
  \clearfield{pages}%
  \clearfield{volume}%
  \clearfield{number}%
  \clearfield{doi}%
  \clearfield{journal}%
  \clearlist{journal}%
  \clearfield{booktitle}%
  \clearfield{isbn}%
  \clearfield{title}%
  \clearfield{url}%
\ifentrytype{article}{
    \clearfield{journal}%
}{}
\ifentrytype{inproceedings}{
    \clearfield{booktitle}%
}{}
}

\begin{document}

\begin{frame}
\maketitle
\end{frame}

\begin{frame}
	\frametitle{Music source separation, demixing, and unmixing}
	Music source separation:
	\begin{enumerate}
		\item
			Extract an estimate of isolated sources (or targets) from mixed musical audio (e.g., harmonic/percussive, vocals, drums, bass, piano)
		\item
			Popular approach: musical source models, which are ``model-based approaches that attempt to capture the spectral characteristics of the target source'' \footcite[36]{musicsepgood} with \textbf{time-frequency masks}, nowadays estimated with DNN (Deep Neural Networks)
	\end{enumerate}
	In music demixing (or unmixing), we estimate multiple sources (vocals, drums, bass, other\footcite{musdb18hq}) that can be summed back to the original mix. Multiple MSS subproblems, reversing the linear mixing of stems in the recording studio (stem datasets can be used for mixing and demixing)
	\begin{figure}[ht]
		\centering
		\vspace{-0.5em}
		\includegraphics[width=7.5cm]{./images-mss/mixdemix.png}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{Music source separation with spectrograms}
	\begin{figure}
		\centering
		\vspace{-1.25em}
		\subfloat{\includegraphics[width=4.25cm]{./images-mss/mss1.png}}
		\subfloat{\includegraphics[width=4.5cm]{./images-mss/mss2.png}}\\
		\vspace{-1em}
		\subfloat{\includegraphics[width=8.75cm]{./images-mss/mask_simple.png}}\\
		\vspace{-0.75em}
		\subfloat{\includegraphics[width=6.5cm]{./images-mss/mssdnn.png}}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{Phase performance ceiling}
	\begin{enumerate}
		\item
			Simplifying assumption: estimate magnitude spectrograms, use the phase of the original mixed audio. Called ``noisy phase'' \footcite{noisyphase1}. Done by both Open-Unmix (UMX) and CrossNet-Open-Unmix (X-UMX) \footcite{umx, xumx}, popular \& near-SOTA models
		\item
			Why? Phase is hard to model!\footnote{\url{https://source-separation.github.io/tutorial/basics/phase.html\#why-we-don-t-model-phase}}
	\end{enumerate}
	\begin{figure}[ht]
		\centering
		\includegraphics[width=7.5cm]{./images-mss/whynophase.png}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{MDX 21 winners and current trends}
	\begin{enumerate}
		\item
			Previously, music demixing systems were submitted to and evaluated at SiSEC (Signal Separation Evaluation Campaign). This year: MDX (Music Demixing Challenge) ISMIR 2021 @ AICrowd, follow-up MDX21 workshop, satellite @ ISMIR 2021
		\item
			\textbf{ISMIR 2021}: Model that uses the complex spectrogram (i.e. includes phase) and uses complex masks\footcite{kong2021decoupling}
		\item
			\textbf{MDX21}: 1: Demucs++\footcite{demucsplus} (waveforms + complex spectrogram), 2: KUIELAB-MDX-Net \footcite{choi2021} (waveforms + magnitude spectrogram), 3: Danna-Sep\footcite{dannasep} (waveform + magnitude spectrogram, use complex spectrogram in loss function)
	\end{enumerate}
	Properties in common: blending networks, waveforms (implicitly includes phase), complex spectrograms/masks, mixing spectrogram and waveform models
\end{frame}

\begin{frame}
	\frametitle{Time-frequency analysis and the uncertainty principle}
	\begin{enumerate}
		\item
			Interesting sounds (music, speech) have frequencies that vary with time, yet Fourier analysis has no temporal information (infinite sinusoids)
		\item
			Short-time Fourier transform (STFT) splits the audio into windows and gets the frequencies of each frame with a Fourier transform
		\item
			``Although we can carry out the analysis [of the acoustic signal] with any degree of accuracy in the time direction or frequency direction, we cannot carry it out simultaneously in both beyond a certain limit'' \footcite[432]{gabor1946}
		\item
			Because time and frequency are Fourier duals of each other, i.e. mutually exclusive domains

	\end{enumerate}
	\begin{figure}[ht]
		\centering
		\vspace{-0.75em}
		\includegraphics[width=7.5cm]{./images-tftheory/gabor3.png}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{TF tradeoff in the STFT}
	Change window size to create time-frequency tradeoff:
	\begin{figure}[ht]
		\centering
		\vspace{-1.25em}
		\subfloat{\includegraphics[height=2.75cm]{./images-gspi/glock_stft_4096.png}}
		\hspace{0.5em}
		\subfloat{\includegraphics[height=2.75cm]{./images-gspi/glock_stft_256.png}}\\
		\vspace{-0.75em}
		\subfloat{\includegraphics[height=2.25cm]{./images-tftheory/gabor4.png}}
		\vspace{-0.25em}
	\end{figure}
	In music source separation, window size matters per-target.\footcite{tftradeoff1} Short-window for percussion, long-window for harmonic\footcite{driedger}
\end{frame}

\begin{frame}
	\frametitle{Constant-Q transform}
	\begin{enumerate}
	\item
		From musical and auditory perspectives, we want high frequency resolution at low frequencies (for the harmonic basis) and high time resolution at high frequency (percussion, transients) \footcite{cqtransient, doerflerphd}
	\item
		CQT\footcite{jbrown, klapuricqt} uses long windows in low frequencies and short windows in high frequencies for the 12-tone Western pitch scale
	\item
		Nonstationary Gabor Transform (NSGT)\footcite{balazs}, sliCQ Transform\footcite{slicq}; motivated by the CQT, but can use arbitrary frequency scales
	\item
		TF transforms with Fourier coefficients, perfect inverse, and varying windows to create a varying time-frequency resolution
	\end{enumerate}
\end{frame}

\begin{frame}
	\frametitle{STFT vs. sliCQT}
	\begin{figure}[ht]
		\centering
		\includegraphics[height=3.3cm]{./images-mml-presentation/spectrograms_comparison.png}
		\vspace{-0.85em}
	\end{figure}
	\begin{enumerate}
		\item
			Note the sliCQT has appropriate time-frequency resolution by auditory or musical principles, containing the best of a short-window and long-window STFT and resulting in increased musical information
		\item
			Parameters found by maximizing the noisy-phase, i.e., find the sliCQT where discarding the phase isn't such a big deal. \textbf{7.42 dB} vs. 6.23 dB of STFT (median on all 4 targets on MUSDB18-HQ validation set)
		\item
			Goal: improve UMX\footcite{umx} by replacing STFT with sliCQT
	\end{enumerate}
\end{frame}

\begin{frame}
	\frametitle{xumx-sliCQ}
	\begin{enumerate}
		\item
			My model submitted to the MDX21 challenge and workshop: \url{https://github.com/sevagh/xumx-sliCQ}
		\item
			Use Convolutional Denoising Autoencoder\footcite{plumbley1, plumbley2} neural architecture
		\item
			Scored 3.6 dB vs. 4.6 dB (UMX) and 5.54 dB (X-UMX); there is still room for improvement
	\end{enumerate}
	\begin{figure}[ht]
		\centering
		\vspace{-1.15em}
		\subfloat{\includegraphics[width=8cm]{./images-blockdiagrams/generic_mdx.png}}\\
		\vspace{-0.5em}
		\subfloat{\includegraphics[width=8cm]{./images-blockdiagrams/umx_clean.png}}\\
		\vspace{-0.5em}
		\subfloat{\includegraphics[width=8cm]{./images-blockdiagrams/xumx_slicq_clean.png}}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{sliCQT challenges}
	Working with a ragged/nonuniform time-frequency transform, noninvertible 50\% overlap-add
	\begin{figure}[ht]
		\centering
		\vspace{-0.75em}
		\subfloat{\includegraphics[width=5cm]{./images-gspi/gspi_overlap_flatten.png}}
		\hspace{0.25em}
		\subfloat{\includegraphics[width=6.75cm]{./images-blockdiagrams/slicq_shape.png}}\\
		\vspace{-0.25em}
		\subfloat{\includegraphics[width=10cm]{./images-blockdiagrams/xumx_slicq_pertarget_largefont.png}}
	\end{figure}
\end{frame}

\end{document}
