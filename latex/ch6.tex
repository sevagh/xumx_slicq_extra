\documentclass[report.tex]{subfiles}
\begin{document}

\begin{appendices}

\section{Testbench computer specifications}
\label{appendix:computerspec}

The hardware and software specifications of the computer which produced the results shown throughout this thesis are as follows:
\begin{tight_itemize}
	\item
		Motherboard: Gigabyte Aorus X570 Elite Wifi
	\item
		CPU: AMD Ryzen 5950X
	\item
		Memory: 64GB DDR4
	\item
		Storage: 1TB ADATA SX8200PNP NVMe
	\item
		GPU, primary: NVIDIA RTX 3080 Ti (12GB memory)
	\item
		GPU, secondary: NVIDIA RTX 2070 Super (8GB memory)
	\item
		OS: Fedora 34 Workstation Edition, 64-bit
	\item
		Linux kernel version: 5.133.10-200
	\item
		Python 3 version: 3.9.6 (default, Jul 16 2021, 00:00:00)
	\item
		NVIDIA driver version: 470.63.01
	\item
		NVIDIA CUDA toolkit version: 11.4
\end{tight_itemize}

\newpagefill

\section{Code availability}
\label{appendix:codeavail}

The code projects associated with this thesis are published as open-source software to encourage reproducibility of results.

They are split across the following projects:
\begin{tight_itemize}
	\item
		NSGT/sliCQT PyTorch copy from sections \ref{sec:torchslicq} and \ref{sec:improvelib}:\\
		\url{https://github.com/sevagh/nsgt}
	\item
		museval (BSS metrics evaluation) CuPy copy from Section \ref{sec:fasterbsscupy}:\\
		\url{https://github.com/sevagh/sigsep-mus-eval}
	\item
		xumx-sliCQ neural network from Section \ref{sec:neuralnet}:\\
		\url{https://github.com/sevagh/xumx-sliCQ}
	\item
		LaTeX files and scripts for generating this thesis, including all plots and demixing results in Chapter \ref{ch:experiment}:\\
		\url{https://gitlab.com/sevagh/xumx_slicq_extra}
	\item
		Submissions made to the ISMIR 2021 Music Demixing Challenge (see Appendix \ref{appendix:crazyexperiments}):\\
		\url{https://gitlab.aicrowd.com/sevagh/music-demixing-challenge-starter-kit}
\end{tight_itemize}

All Python environments were designed to be reproducible with pip requirements.txt files or Conda environment files bundled with the source code:

\begin{tight_itemize}
	\item
		Pip file for oracles, trained model evaluations, boxplot creation, and performance benchmarks:\\
		\url{https://gitlab.com/sevagh/xumx_slicq_extra/-/blob/main/mss_evaluation/mss-oracle-experiments/requirements-cupy.txt}
	\item
		Conda environment file for the NSGT/sliCQT PyTorch implementation:\\
		\url{https://github.com/sevagh/nsgt/blob/main/conda-env.yml}
	\item
		Conda environment file for the xumx-sliCQ neural network:\\
		\href{https://github.com/sevagh/xumx-sliCQ/blob/main/scripts/environment-gpu-linux-cuda11.yml}{https://github.com/sevagh/xumx-sliCQ/blob/main/scripts/environment-gpu-linux-cuda11.yml}
\end{tight_itemize}

I take code availability and reproducibility seriously. Feel free to e-mail me\footnote{\href{mailto:sevag.hanssian@mail.mcgill.ca}{sevag.hanssian@mail.mcgill.ca}, \href{mailto:sevagh+thesis@pm.me}{sevagh+thesis@pm.me}} if you encounter any errors, discrepancies, or difficulties with reproducing any of the results.

\newpagefill

\section{Octave scale for the NSGT}
\label{appendix:octscale}

The octave scale for the NSGT takes a bins-per-octave (bpo) argument from which the total number of frequency bins is computed. Equation \eqref{equation:bpo1} describes how to compute the total bins from the bins-per-octave setting of the octave scale:
\begin{align}
	K = [B \log_{2}(\sfrac{\xi_{\text{max}}}{\xi_{\text{min}}}) + 1]\tag{1}\label{equation:bpo1}
\end{align}

where $K$ is the total bins, $B$ is the bins-per-octave, and $\xi_{\text{min,max}}$ are the minimum and maximum frequencies. This equation was shown previously in equation \eqref{equation:bpo} in Section \ref{sec:cqt}.

By contrast, the logarithmic scale takes the total number of frequency bins as a direct argument. Examples of the octave and logarithmic scales are shown in Figure \ref{fig:octvlog}.

\begin{figure}[ht]
	\centering
	\includegraphics[width=0.9375\textwidth]{./images-freqscales/log_vs_oct.png}
	\caption{The octave and log scales compared. The minimum frequency for both scales is set to $\xi_{\text{min}}$ = 82.41 Hz, which is the frequency of the $E2$ musical note. The maximum frequency for both scales is set to $\xi_{\text{max}}$ = 7,902.13 Hz, which is the frequency of the $B8$ musical note. Note that both scales are identical. The octave scale uses $B = 3 \text{ bpo}$, resulting in $K = 21 \text{ frequency bins}$, from equation \eqref{equation:bpo1}. The log scale uses 21 frequency bins.}
	\label{fig:octvlog}
\end{figure}

\newpagefill

\section{sliCQT dimensionality: fixing $f_{\text{max}}$ to the Nyquist rate}
\label{appendix:slicqdim1}

In Section \ref{sec:slicqparamsrch}, I described that in the parameter search for the frequency scale of the sliCQT, the maximum frequency $f_{\text{max}}$ was fixed to 22,050 Hz (the Nyquist rate of the 44,100 Hz sample rate of the music data set), because it led to a smaller sliCQT than $f_{\text{max}} < 22,050 \text{ Hz}$ in several cases. Note that this is not always true, and depends on the other sliCQT parameters. Out of 809 examples evaluated for this section, 51 of them had a larger transform with the smaller value of $f_{\text{max}}$, and 758 of them (the majority) had a smaller transform when using the smaller value of $f_{\text{max}}$. The evaluation was done on one song from the MUSDB18-HQ dataset, ``Skelpolu - Human Mistakes,'' which has a duration of 324.69 seconds, or 14,318,640 samples at a 44,100 Hz sample rate.

Table \ref{table:slicqdimdegen1} shows some examples of sliCQT parameters for the Constant-Q scale from the more rare case where a larger frequency range with $f_{\text{max}} = \text{Nyquist rate}$ led to a smaller transform than a smaller frequency range with $f_{\text{max}} < \text{Nyquist rate}$. Table \ref{table:slicqdimdegen2} shows more typical counter-examples, where smaller frequency ranges result in smaller transforms.

\begin{table}[ht]
	\centering
	\caption{sliCQT examples where $f_{\text{max}} = \text{Nyquist rate}$ resulted in a smaller transform.}
	\label{table:slicqdimdegen1}
\begin{tabular}{ |l|l|l|l|l| }
	 \hline
	 Total bins & $f_{\text{min}}$ (Hz) & $f_{\text{max}}$ (Hz) & Number of coefficients \\
	 \hline
	 \hline
	 11 & 96.8 & 14,771.2 & 214,263,720 \\
	 \hline
	 11 & 96.8 & 22,050 & 182,892,400 (-14\%) \\
	 \hline
	 \hline
	 26 & 27.7 & 18,202.8 & 320,350,992 \\
	 \hline
	 26 & 27.7 & 22,050 & 294,027,200 (-8\%) \\
	 \hline
	 \hline
	 64 & 106.7 & 20,962.8 & 292,568,064 \\
	 \hline
	 64 & 106.7 & 22,050 & 281,151,360 (-3.7\%) \\
	 \hline
	 \hline
	 203 & 74.4 & 21,726 & 323,409,856 \\
	 \hline
	 203 & 74.4 & 22,050 & 318,891,744 (-1.5\%) \\
	 \hline
\end{tabular}
\end{table}

\begin{table}[ht]
	\centering
	\caption{sliCQT examples where $f_{\text{max}} = \text{Nyquist rate}$ resulted in a larger transform.}
	\label{table:slicqdimdegen2}
\begin{tabular}{ |l|l|l|l|l| }
	 \hline
	 Total bins & $f_{\text{min}}$ (Hz) & $f_{\text{max}}$ (Hz) & Number of coefficients \\
	 \hline
	 26 & 88.4 & 20,341.5 & 299,574,080 \\
	 \hline
	 26 & 88.4 & 22,050 & 329,643,392 (+10\%) \\
	 \hline
	 \hline
	 135 & 23.4 & 18,935.7 & 334,379,880 \\
	 \hline
	 135 & 23.4 & 22,050 & 397,612,800 (+18\%) \\
	 \hline
	 \hline
	 289 & 36.8 & 18,874.5 & 310,746,672 \\
	 \hline
	 289 & 36.8 & 22,050 & 362,147,328 (+16\%) \\
	 \hline
\end{tabular}
\end{table}

\newpagefill

\section{STFT and sliCQT dimensionality compared}
\label{appendix:slicqdim2}

In Section \ref{sec:replacestft}, I described that X-UMX uses the STFT of six-second audio sequences as its input, and that I had to use one second sequences for the sliCQT in xumx-sliCQ so that it could fit in the GPU memory during training. This is because the sliCQT of an audio sequence is larger than the STFT. In this section, I will show several different configurations of sliCQT to support this claim.

Out of 122 examples evaluated for this section, in every single case the sliCQT was larger than the STFT. The evaluation was done on one song from the MUSDB18-HQ dataset, ``Skelpolu - Human Mistakes,'' which has a duration of 324.69 seconds, or 14,318,640 samples at a 44,100 Hz sample rate.

Table \ref{table:slicqdimstft1} shows some examples of sliCQT parameters for the Constant-Q scale compared to the dimensionality and number of coefficients of the STFT. Alongside the STFT with a window size of 4,096 samples and overlap of 1,024 samples as used by X-UMX, I included a smaller STFT with a window size of 1,024 and overlap of 256 samples, and a larger STFT with a window size of 8,192 and an overlap of 2,048 samples.

\begin{table}[ht]
	\centering
	\caption{sliCQT examples with the Constant-Q scale, compared to the STFT.}
	\label{table:slicqdimstft1}
\begin{tabular}{ |l|l|l| }
	 \hline
	 Transform & Tensor shape & Number of coefficients \\
	 \hline
	 \hline
	 STFT, 1024 & (2, 513, 18646) & 19,130,796  \\
	 \hline
	 STFT, 4096 & (2, 2049, 4663) & 19,108,974  \\
	 \hline
	 STFT, 8192 & (2, 4097, 2332) & 19,108,408  \\
	 \hline
	 \hline
	 sliCQT, 91 bins, 107.13--10078.31 Hz & (880, 2, 91, 752) & 120,440,320 \\
	 \hline
	 sliCQT, 20 bins, 39.75--22050 Hz & (2157, 2, 19, 3184) & 260,979,744 \\
	 \hline
	 sliCQT, 171 bins, 58.14--22050 Hz & (331, 2, 171, 3036) & 343,681,272 \\
	 \hline
	 sliCQT, 25 bins, 20.43--22050 Hz & (970, 2, 25, 8632) & 418,652,000 \\
	 \hline
\end{tabular}
\end{table}

\newpagefill

\section{xumx-sliCQ experiments}
\label{appendix:crazyexperiments}

In Section \ref{sec:slicqarches}, I mentioned a repeated tuning process where I evaluated different neural network architectures and parameters for xumx-sliCQ. In this appendix, I will describe the nature of these experiments.

Before starting this thesis in May 2021, I worked on two related projects; a project\footnote{\url{https://github.com/sevagh/MiXiN}} which used the NSGT (Nonstationary Gabor Transform) for music demixing using a CDAE (convolutional denoising autoencoder) neural architecture, and a project\footnote{\url{https://github.com/sevagh/Music-Separation-TF}} which explored different time-frequency transforms and the time-frequency tradeoff in music source separation algorithms based on spectrogram masking. In the second project, I used Open-Unmix as a high-performance baseline.

In May 2021, Sony, the major Japanese technology company,\footnote{\url{https://www.sony.com/en/}} and Inria, a French national research institution,\footnote{\url{https://www.inria.fr/en}} sponsored a music demixing research challenge on the crowdsourced AI platform, AIcrowd.\footnote{\url{https://www.aicrowd.com/challenges/music-demixing-challenge-ismir-2021}} The challenge was called the ISMIR 2021 MDX (Music Demixing) Challenge, with an associated satellite workshop planned for the ISMIR 2021 conference.

The participants were encouraged to either modify the baselines (like Open-Unmix) or submit their own custom code to win the challenge. The MDX challenge ran from May to July 2021, giving participants three months to work on their neural networks. I chose to align my master's thesis project with the challenge, and made my goal the modification of Open-Unmix to use the sliCQT (sliced Constant-Q Transform).

The collaborative environment of the challenge was very fun, and I made 32 total submissions\footnote{\url{https://gitlab.aicrowd.com/sevagh/music-demixing-challenge-starter-kit}} to the challenge, resulting in a final place of 34 on the leaderboard. In my submission process, I tested different neural architectures and parameters with both the CDAE and Bi-LSTM variants until one of them achieved good results.

My work in the challenge resulted in the creation of xumx-sliCQ,\footnote{\url{https://github.com/sevagh/xumx-sliCQ}} the final model of this thesis. I wrote an article on xumx-sliCQ,\footnote{\url{https://mdx-workshop.github.io/proceedings/hanssian.pdf}, \url{https://arxiv.org/abs/2112.05509}} and I participated in the virtual ISMIR 2021 conference, where I showed xumx-sliCQ at the poster session\footnote{\url{https://gitlab.com/sevagh/xumx_slicq_extra/-/blob/main/drafts-and-blobs/mdx21-poster.pdf}} of the MDX 21 challenge.

\end{appendices}

\end{document}
