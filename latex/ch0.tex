\documentclass[report.tex]{subfiles}
\begin{document}

\renewcommand{\abstractname}{Acknowledgement}
\begin{abstract}
\phantomsection
\addcontentsline{toc}{section}{\abstractname}
I would like to thank my supervisor, Professor Ichiro Fijunaga, for providing guidance throughout my master's degree and thesis. His rigor and attention to detail have made me a better researcher. Next, I owe thanks to my labmates at the Distributed Digital Music Archives \& Libraries Lab (DDMAL), who were always available to help; N{\'e}stor N{\'a}poles L{\'o}pez, Timothy de Reuse, Emily Hopkins, and all the others. In the McGill Music Technology department, Professor Philippe Depalle helped me hone my signal processing knowledge, and Professor Gary Scavone's emphasis on creativity allowed me to do my best work. I would also like to thank my family and close friends for their unconditional support and encouragement.\\

Finally, I am grateful to the open-source community for music source separation research, including the SigSep organization\footnote{\url{https://github.com/sigsep}} on GitHub, which provides high-quality code to accompany academic papers, and the 2021 Music Demixing challenge,\footnote{\url{https://mdx-workshop.github.io/}} which encouraged open-source contributions and fostered a collaborative environment.
\end{abstract}

\newpagefill

\renewcommand{\abstractname}{Abstract}
\begin{abstract}
\phantomsection
\addcontentsline{toc}{section}{\abstractname}
	Music source separation is the task of extracting an estimate of one or more isolated sources or instruments (for example, drums or vocals) from musical audio. The task of music demixing or unmixing considers the case where the musical audio is separated into an estimate of all of its constituent sources that can be summed back to the original mixture. Models for music demixing that use the Short-Time Fourier Transform (STFT) as their representation of music signals are popular and have achieved success in recent years. However, the fixed time-frequency resolution of the STFT, arising from the time-frequency uncertainty principle, requires a tradeoff in time-frequency resolution that can significantly affect music demixing results. The sliced Constant-Q Transform (sliCQT) is a time-frequency transform with varying time-frequency resolution that avoids the time-frequency tradeoff of the STFT. The model proposed by this thesis replaces the STFT with the sliCQT in a recent model for music demixing, to investigate the impact on the results.
\end{abstract}

\newpagefill

\renewcommand{\abstractname}{R{\'e}sum{\'e}}
\begin{abstract}
\phantomsection
\addcontentsline{toc}{section}{\abstractname}
	La séparation de sources musicales consiste à extraire d’un enregistrement audio une ou plusieurs sources ou instruments de musique (tels que des percussions ou de la voix). Plus spécifiquement, la tâche de démixage correspond au cas où l’enregistrement audio est séparé en toutes ses sources constitutives, qui peuvent être re-mixées pour restituer l’ensemble original. Les modèles de démixage de musique qui se fondent sur la transformée de Fourier à court-terme (TFCT) pour représenter les signaux sonores sont populaires et ont été utilisées avec succès au cours des dernières années. Toutefois, le compromis entre résolution temporelle et résolution fréquentielle préfixé dans la TFCT, résultant du principe d’incertitude temps-fréquence, peut affecter considérablement les résultats du démixage audio. La transformée en tranche à facteur de qualité constant (sliCQT) est une transformée temps-fréquence pour laquelle le compromis entre résolutions temporelle et fréquentielle varie selon la région spectrale considérée, ce qui permet une plus grande flexibilité d’approche qu’avec la TFCT. Le modèle proposé dans cette thèse remplace la TFCT par la sliCQT dans un modèle de démixage audio et évalue l’impact de ce choix sur les résultats.
\end{abstract}

\end{document}
