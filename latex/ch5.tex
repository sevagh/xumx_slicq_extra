\documentclass[report.tex]{subfiles}
\begin{document}

\section{Conclusion}
\label{sec:conclusion}

In the task of music demixing, a mixed song is separated into estimates of its isolated constituent sources or instruments that can be summed back to the original mixture. A common approach to music demixing is to apply a mask to the spectrogram of the mix to extract the desired source. Two models for music demixing are Open-Unmix (UMX) and its closely-related variant CrossNet-Open-Unmix (X-UMX), both of which use spectrogram masking with the Short-Time Fourier Transform (STFT). The STFT has known limitations that arise from its fixed time-frequency resolution, and different sources or instruments may have conflicting needs for the time-frequency resolution of their STFT for better separation results.

Methods of music demixing based on the STFT have addressed the time-frequency limitation by using multiple STFTs, or by using different time-frequency transforms like the Constant-Q Transform (CQT). The CQT has a varying time-frequency resolution, where low-frequency regions are analyzed with a high frequency resolution, and high-frequency regions are analyzed with a high time resolution, which is appropriate for both musical and auditory analysis.

The sliced Constant-Q Transform (sliCQT) is a realtime implementation of the Nonstationary Gabor Transform (NSGT). The NSGT and sliCQT provide a method for computing time-frequency transforms with complex-valued Fourier coefficients and a perfect inverse. They were originally designed to implement an invertible CQT, but they support arbitrary nonuniform frequency scales (e.g., psychoacoustic scales like the mel and Bark scales).

In this thesis, the sliCQT was explored as a replacement of the STFT in UMX and X-UMX, in a newly proposed model called xumx-sliCQ. The goal was to use the sliCQT with an custom frequency scale to see if it could improve on the STFT-based music demixing performance of UMX and X-UMX. Unfortunately, the proposed model, xumx-sliCQ, performed worse than UMX and X-UMX. However, the creation of xumx-sliCQ in this thesis led to several contributions to the current Python ecosystem of music demixing.

First, the PyTorch implementation of the NSGT/sliCQT allows these transforms to be used in future GPU neural networks, and it sped up the computation of the transforms compared to the original library by \textasciitilde4x. Second, the GPU speedup of the BSS (Blind Source Separation) metrics library can speed up evaluations of music demixing and source separation by \textasciitilde2x. Finally, xumx-sliCQ demonstrated the first working prototype of a sliCQT-based deep neural network for music demixing. Different frequency scales or network architectures may achieve greater success in the future.

\end{document}
