\documentclass[report.tex]{subfiles}
\begin{document}

\todo[inline]{
General tips:\\
  Switch passive voice and we to I\\
  Re-spell acronyms at the beginning of Chapter\\
 Chapter tips:\\
   Why is CuPy BSS acceleration good? param search and also evaluation\\
   Discard/simplify post-processing stuff wiener ragged etc.\\
   Redo neural section in the correct order of ch4\\
   More redundancy (restate hypothesis, goals)
}
\section{Discussion and conclusion}

In this section, we will discuss the results shown in Section \ref{sec:experiment}, and conclude this thesis.

\subsection{Discussion of results}
\label{sec:discussion}

\subsubsection{sliCQT PyTorch port}
\label{sec:gpuexperimentpytorchdiscuss}

In Section \ref{sec:gpuexperimentpytorch}, the results of the benchmarks were shown for the two GPU porting efforts, which were the PyTorch port of the NSGT/sliCQT library from Section \ref{sec:torchslicq} and the CuPY port of the BSS metrics evaluation library from Section \ref{sec:fasterbsscupy} respectively.

Table \ref{table:nsgttorchresultsragged} from Section \ref{sec:gpuexperimentpytorch} contained the benchmark results for the PyTorch implementation of the ragged sliCQT compared to the original library. The execution time of the transform improved with PyTorch in every case. The transform computed with PyTorch on the CPU was \textasciitilde4.7x faster than the single-threaded CPU implementation of the original library. The transforms computed with PyTorch on the GPUs were \textasciitilde3.5x and \textasciitilde3.7x faster than the single-threaded CPU implementation of the original library respectively.

Even though the sliCQT computed with PyTorch on the GPU was not faster than the CPU for the tested parameters, having the transform on the GPU allows us to use the sliCQT inside a PyTorch neural network. We note that the original library has a multithreaded option which performs worse than the default single-threaded behavior, which was an unexpected result. It might be explained by the overhead of multithreading.

\subsubsection{Best sliCQT parameters}
\label{sec:slicqparamresultsdiscuss}

In Section \ref{sec:slicqparamresults}, the results of the random grid search for the best-performing sliCQT parameters for the MPI oracle in Section \ref{sec:slicqparamsrch} were shown. The best-performing sliCQT chosen by the script had the parameters of 262 bins between 32.9--22050 Hz on the Bark scale.

The sliCQT MPI oracle results for the above sliCQT achieved a median SDR of 7.42 dB. This surpassed the MPI oracle score of 6.23 dB achieved by the STFT with the UMX settings of a window size of 4096 and overlap of 1024. This indicates that a music demixing system that uses the sliCQT with these parameters has the potential to surpass the STFT-based performance.

Keep in mind that to translate this theoretical boost to a real advantage in the final model, a neural network architecture must be chosen that can produce a good estimate of the target magnitude sliCQT. Note the sharper clarity of musical events in both time and frequency in the sliCQT spectrogram in Figure \ref{fig:bipolarslicqs}(a) compared to the STFT spectrogram in Figure \ref{fig:bipolarslicqs}(b). We hope that this added information gives the neural network an advantage when learning how to demix music from the sliCQT representation compared to the STFT.

\subsubsection{CuPy PyTorch port}
\label{sec:cupyportbssdiscuss}

Section \ref{sec:cupyportbss} described the benchmarking of the GPU-accelerated BSS metrics library using CuPy.\footnote{\url{https://github.com/sevagh/sigsep-mus-eval}} The results showed a \textasciitilde2-2.5x speedup with GPU over the CPU, which represent a significant reduction in the time taken to evaluate music demixing systems. This speedup can be useful for various evaluation campaigns like SiSEC \parencite{sisec2018} or MDX \parencite{mdx21}.

\subsubsection{xumx-sliCQ neural network}
\label{sec:netdiscuss}

In Section \ref{sec:postprocessing}, I showed two implementation choices for the Wiener-EM post-processing step in xumx-sliCQ; one which could be computed on the sliCQT directly, and one which swapped from the sliCQT domain to the STFT domain to perform Wiener-EM.

Firstly, the zero-padded matrix form of the sliCQT-Wiener-EM was \textasciitilde2x faster than the ragged sliCQT-Wiener-EM, with an almost neglibile improvement of 0.005 dB in the SDR score for the tested track for one iteration. For this reason, the zero-padded sliCQT-Wiener-EM was the chosen implementation of sliCQT-based Wiener-EM in the final model, and the ragged sliCQT-Wiener-EM was discarded for being too computationally slow.

Next, the STFT-Wiener-EM step with one iteration scored 0.073 dB lower than the zero-padded matrix form of sliCQT-Wiener-EM, but was \textasciitilde1.25x faster. We chose to use the STFT-Wiener-EM strategy as the default for the best tradeoff between music demixing performance and computation time, and to add a parameter called \Verb#slicq_wiener#\footnote{\url{https://github.com/sevagh/xumx-sliCQ/blob/main/xumx_slicq/model.py\#L380}} to use the zero-padded sliCQT-Wiener-EM for a computation time hit but SDR improvement.

For both STFT and sliCQT-based Wiener-EM, two iterations were worse than one iteration, so the default was left at one in xumx-sliCQ.

In Section \ref{sec:demixresults}, the music demixing results for trained xumx-sliCQ model were shown, using the CDAE architecture which was fully trained with 1,000 epochs to the lowest loss of -0.449 epochs shown in Section \ref{sec:networktraining}. Both strategies of post-processing were evaluated. Table \ref{table:bsseval} from Section \ref{sec:demixresults} showed that xumx-sliCQ performed worse than UMX and X-UMX, with both STFT-Wiener-EM and sliCQT-Wiener-EM post-processing. The median SDR of xumx-sliCQ was 3.6 dB with the STFT-Wiener-EM step, and 3.71 dB with the sliCQT-Wiener-EM. Compared to UMX which scored 4.64 dB and X-UMX which scored 5.54 dB, we can see that xumx-sliCQ failed in its objective to surpass UMX and X-UMX.

Finally, in Section \ref{sec:inferenceperf}, we showed results for the running time of the inference, as well as the size of the trained models on disk. The STFT-Wiener-EM configuration of xumx-sliCQ runs \textasciitilde2x slower than UMX, and the sliCQT-Wiener-EM configuration runs \textasciitilde4x slower than UMX. We note that the sliCQT-Wiener-EM configuration only adds \textasciitilde0.1 dB to the median SDR score compared to the STFT-Wiener-EM variant, which is a poor tradeoff considering it doubles the running time.

We also note that X-UMX shows an anomalously high execution time, measuring at almost \textasciitilde20x slower than UMX, but this is because it uses a different deep learning framework, NNabla, which cannot be directly compared to PyTorch.

xumx-sliCQ's main advantage over UMX and X-UMX is in the size of the trained model. It is \textasciitilde4.9x smaller on disk than both of the original STFT-based models, using 28 MB instead of the 137 and 136 MB of UMX and X-UMX respectively.

\subsection{Conclusion}
\label{sec:conclusion}

The creation of xumx-sliCQ led to several contributions to the current Python ecosystem for music demixing. First, the PyTorch implementation of the NSGT/sliCQT allow these transforms to be used in GPU machine learning and deep learning networks, and improves the performance by \textasciitilde3.4-4.7x over the original library, depending on whether the CPU or GPU is used. Second, the CuPy implementation of the BSS metrics library sped up the evaluation of music demixing by 2-2.5x. Finally, xumx-sliCQ demonstrated the first working prototype of a sliCQT-based music demixing neural network using the GPU and PyTorch.

Unfortunately, the proposed model, xumx-sliCQ, failed to beat the BSS metrics scores of Open-Unmix (UMX) and CrossNet-Open-Unmix (X-UMX).

\subsection{Summary and outlook}

The STFT has known limitations that arise from its fixed time-frequency resolution. Methods of spectral music demixing that use the STFT have addressed this limitation by using multiple STFTs or by using different time-frequency transforms like the CQT. In many STFT-based models for music demixing, the phase is discarded for simplicity and the network operates on the magnitude STFT.

The advantage of the sliCQT is that it can provide a method for computing a time-frequency transform with the familiar complex-valued Fourier coefficients and a perfect inverse operation for arbitrary frequency scales. The signal or application under study can dictate the frequency scale used. The goal of using the sliCQT in a music demixing application was to see if the improved time-frequency resolution, and an appropriately-chosen frequency scale, could improve the performance of STFT-based models.

In this thesis, two near-SOTA STFT-based models, Open-Unmix (UMX) and its closely-related variant CrossNet-Open-Unmix (X-UMX), were adapted to use the sliCQT and create a new model for music demixing called xumx-sliCQ. xumx-sliCQ did not surpass UMX and X-UMX, but we believe it represents a promising start to sliCQT-based music demixing techniques.

Looking towards the future, a direction to explore is using the improved variant of the NSGT/sliCQT \parencite{variableq1}, which is the CQ-NSGT implementation used in the cqt function of the MATLAB Wavelet Toolbox.\footnote{\url{https://www.mathworks.com/help/wavelet/ref/cqt.html}} A matrix form is proposed which uses rasterization, or interpolation, of the low-frequency bins to match the larger size of time coefficients of the high-frequency regions. This would create a single matrix for the sliCQT, eliminating the challenges of working with the ragged shape of the transform in this paper. \textcite{variableq1} also proposed to improve the phase of the transform, which may affect the quality of the time-domain waveform estimate from the mix-phase inversion.

\end{document}
