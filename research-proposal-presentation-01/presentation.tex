\documentclass[usenames,dvipsnames]{beamer}
\usetheme{Boadilla}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{multimedia}
\usepackage{fancyvrb}
\usepackage{multicol}
\usepackage{optparams}
\usepackage{adjustbox}
\usepackage{tikz}
\usetikzlibrary{shapes,positioning}
\newcommand{\foo}{\hspace{-2.3pt}$\bullet$ \hspace{5pt}}
\usepackage{subfig}
\usepackage[
    backend=biber,
    natbib=true,
    style=numeric,
    sorting=none,
    style=verbose-ibid,
    maxcitenames=1, %remove this outside of toy presentations
]{biblatex}
\addbibresource{citations.bib}
\usepackage{pgfpages}
\usepackage{xcolor}
\definecolor{ao(english)}{rgb}{0.0, 0.5, 0.0}
\definecolor{burgundy}{rgb}{0.5, 0.0, 0.13}
%\setbeameroption{show notes}
%\setbeameroption{show notes on second screen=right}
\setbeameroption{hide notes}

\title{Better spectrograms for onset detection and music source separation}
\subtitle{MA Thesis research proposal}
\author{Sevag Hanssian}
\institute{DDMAL, McGill}
\setbeamertemplate{navigation symbols}{}

\AtEveryBibitem{%
  \clearfield{pages}%
  \clearfield{volume}%
  \clearfield{number}%
}

\renewbibmacro{in:}{}

\AtEveryCitekey{%
  \clearfield{pages}%
  \clearfield{volume}%
  \clearfield{number}%
  \clearfield{doi}%
  \clearfield{journal}%
  \clearfield{booktitle}%
}

\begin{document}

\begin{frame}
\maketitle
\end{frame}

\begin{frame}
	\frametitle{My own goals}
	Motivating musical applications based on what I like working on:
	\begin{enumerate}
		\item
			Onset detection (how it relates to the core of beat tracking)
		\item
			Music source separation
	\end{enumerate}

	What I want to do:
	\begin{enumerate}
		\item
			Hypothesis -- ``swap STFT with the CQT in music source separation and onset detection, and get better results''. In other words spectrogram stays spectrogram but the implementation detail of the spectrogram is different.
		\item
			Why CQ-NSGT? perfectly invertible, rectangular time-frequency matrix, which can be used to create a spectrogram, with arbitrary frequency scales. Can use arbitrary frequency bands for the constant-Q factor, e.g. mel/bark/octave/log
		\item
			Get a publishable result by beating the SOTA in something -- ISMIR (too late for 2021), DAFX, IEEE -- or just arXiv first?
	\end{enumerate}
\end{frame}

\begin{frame}
	\frametitle{Judith Brown CQT -- classic paper}
	Classic paper by \footcite{jbrown}, creating a transform which maintained a constant ratio of frequency to frequency resolution:
\begin{itemize}
	\item
		Harmonics of f0 created by musical instruments have a consistent spacing in the log scale (\textit{constant pattern})
	\end{itemize}
	\begin{figure}[ht]
		\vspace{-0.75em}
		\centering
		\subfloat[Linear-frequency DFT]{\includegraphics[height=3cm]{../latex/violindft.png}}
		\hspace{0.5em}
		\subfloat[Constant-Q transform]{\includegraphics[height=3cm]{../latex/violincqt.png}}
		\caption{Violin playing the diatonic scale, $G_{3} \text{(196Hz)} - G_{5} \text{(784Hz)}$}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{Klapuri CQT}
	Klapuri's CQT implementation is used in librosa, and up until recently, in MATLAB's CQT. According to \footcite{cqtklapuri}, ``the CQT is well-motivated from both musical and perceptual viewpoints'':
	\begin{enumerate}
		\item
			\textbf{Frequency spacing for music:} Fundamental frequencies (F0s) of the tones in Western music are geometrically spaced
		 \item
			 \textbf{Frequency spacing for human psychoacoustic auditory system:} From auditory perspective, the frequency resolution of the peripheral hearing system of humans is approx constant-Q (cites B. C. J. Moore)
		 \item
			 \textbf{Sharp transient/temporal resolution:} From perceptual audio coding (cites AAC codec from ISO/IEC), shortest transform window lengths are $\approx$ 3ms to retain high quality, whereas higher frequency resolution is required to carry out coding at low frequencies
		\item
			Contrast with the conventional DFT which has linearly spaced frequency bins and cannot satisfy the \textbf{varying tf resolution} requirements over the wide range of audible frequencies
	\end{enumerate}
\end{frame}

\begin{frame}
	\frametitle{Problems so far}
	Why is the CQT not popular and used everywhere in place of the STFT? According to \footcite{cqtklapuri}:
	\begin{itemize}
		\item
			Computational efficiency - CQT is expensive (jbrown, jbrown + msp paper, followed by klapuri)
		\item
			Imperfect reconstruction - jbrown's is not invertible. Klapuri has error of $10^{-3}$, or 55dB reconstruction - used in librosa. not bad, not good
		\item
			CQT produces a data structure that is more difficult to work with than the time-frequency matrix (spectrogram) obtained by using the STFT in successive time frames.\\
			The last problem is due to the fact that in CQT, the time resolution varies for different frequency bins, in effect meaning that the ``sampling'' of different frequency bins is not synchronized
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{D{\"o}rfler music transform}
	According to \footcite{doerflerphd}, a good transform for music must satisfy two properties (satisfied by two STFTs with two different window size):
\begin{itemize}
	\item
		\textit{Transients} are important musically, driving instrument identification and temporal events such as beats. As transients and broadband signals occur in the high frequency range, good time resolution in that range allows clearer identification of transient events.
	\item
		 Notes in the low frequency lay the harmonic basis of the song, requiring very fine frequency resolution.
\end{itemize}
	This leads to a single transform, the CQT based on the NSGT -- perfect reconstruction using frame theory: \footcite{balazs}, \footcite{invertiblecqt}, now used in MATLAB (not librosa yet)
\end{frame}

\begin{frame}
	\frametitle{Story so far}
	CQT can be good for music:
	\begin{enumerate}
		\item
			Constant-Q frequency spacing, good for Western musical scales and psychoacoustic system both
		\item
			Fine temporal resolution in the high frequency range for transients (attacks, percussion), fine frequency resolution in the low frequency range (for harmonic basis)
	\end{enumerate}
	Some CQT downsides as a STFT replacement are mitigated:
	\begin{enumerate}
		\item
			Perfect inversion solved by NSGT \footcite{invertiblecqt}. Python library: \href{https://github.com/grrrr/nsgt}{https://github.com/grrrr/nsgt}
		\item
			Make it look like an STFT in a rectangular matrix: both contemporary methods do this \footcite{cqtklapuri}, \footcite{invertiblecqt}
		\item
			Still computationally more expensive than the STFT
	\end{enumerate}
\end{frame}

\begin{frame}
	\frametitle{Refined hypotheses}
	\textbf{Music source separation}\\
	Source separation depends on sparsity of musical sources \footcite{musicsepgood}. Having the octave scale might help distinguish musical instrument sources more strongly (e.g. think back on jbrown's violin diagram)\\
	Transients are also important in source separation \footcite{transientsep}, and the CQT inherently contains sharp temporal/transient resolution\\
	\vspace{1em}
	\textbf{Onset detection}\\
	Beat tracking largely depends on onsets, and sharper transient resolution and well-defined notes on a musical scale could allow for better distinguishing of both percussive and non-percussive onsets. Clear SOTA to beat
\end{frame}


\begin{frame}
	\frametitle{Chapter 1 -- time-frequency analysis of music signals and the STFT}
	Intro to discrete-time audio signals, sample rate, Fourier transform, frequency/spectral analysis\\\ \\
	Gabor time-frequency uncertainty principal (and how we have to trade off time vs. frequency in the spectrogram), Gabor transform i.e. the first published use of the STFT, origins of the windowed FFT aka STFT (independently discovered but now merged in a unified theory)\\\ \\
	Common STFT operations or post-processing -- magnitude spectrograms, power spectrograms, mel spectrograms, log spectrograms, mfcc\\\ \\
	Relation to music e.g. large window sizes are used for harmonic instruments (find sources to corroborate this), small window sizes used for percussion (e.g. in music source separation this is very common and i wrote an entire report on this in 622)
\end{frame}

\begin{frame}
	\frametitle{Chapter 2 -- the CQT and NSGT for varying time-frequency analysis}
	History of CQT (jbrown, klapuri, nsgt). NSGT and how the CQT can be written as the NSGT with octave (and log/mel/bark) frequency scales\\\ \\
	Relation to the STFT -- time axis, frequency axis, coefficient values. Dimensionality -- e.g. $N \times M$  STFT matrix $\rightarrow$ $? \times ?$ CQT matrix. Computation: describe how many FFTs are applied, how many windows/filterbank\\\ \\
	Time-frequency properties, quantified -- e.g. ``with a 24-bin CQT, it has 1.3ms transient resolution in the frequency range f1-f2'' Relate this to music, e.g. ``percussion is known to have an attack time of 1.3ms'' or how a wide frequency range is necessary for bass guitar analysis\\
Params: Frequency scales: octave, mel, bark, log. Fmin: 20, 27.5, 32.5 Bins: bins-per-octave, or total bins. 12, 24, 48, 84, 96 are common -- can go ultra-high e.g. 120, 132, 144. compare to known pitch scales or music instrument frequencies
\end{frame}

\begin{frame}
	\frametitle{Chapter 3 -- CQT for onset detection}
	Experiment idea (\textcolor{red}{\textbf{UNVALIDATED}}):
	\begin{enumerate}
		\item
			This paper: \href{https://www.diva-portal.org/smash/get/diva2:1338850/FULLTEXT02}{https://www.diva-portal.org/smash/get/diva2:1338850/FULLTEXT02} tries to recreate B{\"o}ck's state of the art CNN and RNN architectures for onset detection
		\item
			Both architectures use 3 STFTs as input with different window sizes (to vary time-frequency resolution)
		\item
			\textbf{hypothesis} maybe a single CQT has enough time-frequency information as 3 mixed-window STFTs, reducing the network size. maybe the improved transient and clarity of musical notes are beneficial (in fact, they already use log-scale spectrograms (logarithmic = roughly constant-Q) to improve results)
		\item
			First, redo paper recreation (low effort since they documented it very well) -- i.e, get the expected 86\% and 85\% RNN and CNN onset detection F-score with the standard 3 STFT model
		\item
			Second, replace with single-CQT (or multi-CQT) architecture and see what happens
	\end{enumerate}
\end{frame}

\begin{frame}
	\frametitle{Chapter 4 -- CQT for music source separation}
	Idea: replace STFT with CQT in source separation\\
	\vspace{0.5em}
	Without actually working on any single model, we can focus on the IRM -- (oracle) ideal ratio mask, representing the theoretical  best performance of spectral masking based music source separation algorithms \footcite{irm}, \footcite{sigsep2018}, \footcite{vincent07}\\
	\vspace{0.5em}
	Hypothesis: ``is it possible to surpass the best possible music source separation performance based on spectral masking by using CQT masking instead of STFT?''\\
	\vspace{0.5em}
	Bleeding edge -- today, best waveform based NNs (e.g. demucs) tout that they surpassed the previous SOTA spectrogram-based models (2018-2019) by beating the IRM. Tagline of new SOTA end-to-end waveform based models is ``surpassing ideal time-frequency mask''
\end{frame}

\begin{frame}
	\frametitle{Music source separation objective evaluation}
	Evaluations not based on human subjective analysis:
	\begin{itemize}
		\item
			Industry standard is BSS \footcite{bss} used in SiSec 2018 campaign for music source separation \footcite{sigsep2018}. BSS is used for recently published top source separation models -- even in bleeding-edge waveform-based end-to-end neural waveform models: \href{https://github.com/facebookresearch/demucs}{https://github.com/facebookresearch/demucs}
		\item
			Industry standard dataset is MUSDB18 and MUSDB18-HQ \footcite{musdb18, musdb18-hq}
		\item
			Used both in 622 so I'm equipped to evaluate
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Music source separation -- work done so far}
	\begin{itemize}
		\item
			Forked bss eval + nsgt and modified both to use GPU (with CUDA/cupy) to speed up evaluation time (for a single track) from 3.5 minutes down to 1 -- allows for a much bigger testbench
		\item
			Based on sisec's evaluation + boxplot code from the SiSec 2018 paper, e.g.:\\
			\includegraphics[height=3.5cm]{./irm_boxplot_example.png}
		\item
			Plan: compute IRM,IBM\{1,2\} for STFT 2048 (default) (should I mix window sizes here?) followed by various CQT configurations. Take median scores to see how they across bins, frequency scale, fmin -- each parameter. mel, 12 bins -- 144 bins, etc.
	\end{itemize}
\end{frame}

\begin{frame}[fragile]
	\frametitle{contd}
	custom json format for defining testcases:
	\begin{Verbatim}[fontsize=\tiny]
	  {
	    "type": "stft",
	    "name": "stft2048",
	    "window": 2048
	  },
	  {
	    "type": "nsgt",
	    "name": "cq-96-27.5",
	    "scale": "octave",
	    "bins": 96,
	    "fmin": 27.5
	  },
	  {
	    "type": "nsgt",
	    "name": "mel-120-20",
	    "scale": "mel",
	    "bins": 120,
	    "fmin": 20
	  }
	\end{Verbatim}
\end{frame}

\begin{frame}
	\frametitle{Chapter 5 -- results, discussion, conclusion}
	tl;dr thesis:
	\begin{itemize}
		\item
			\textbf{Chapter 1:} Music analysis with the STFT leads to necessary tradeoff of time and frequency resolution (due to theoretical limitations of TF analysis). However, spectrogram/STFT is widely used and ubiquitous
		\item
			\textbf{Chapter 2:} the CQT better represents some musical properties, and can replace the STFT-spectrogram in-place in many algorithms. many configurations of CQ-NSGT (freq range, octave scales, etc.)
		\item
			\textbf{Chapter 3:} Show the success of the NSGT-based (perfect inversion) CQT in SOTA neural network for \textbf{onset detection}
		\item
			\textbf{Chapter 4:} verify whether we can surpass the theoretical maximum performance/IRM of spectrogram-based source separation with the CQT, with a whole bunch of different configurations
		\item
			\textbf{Chapter 5:} discuss and conclude
	\end{itemize}
	\textcolor{red}{\textbf{is this enough to constitute a thesis?}}
\end{frame}

\begin{frame}
	\frametitle{\textbf{optional chapter}: warped-frequency STFT}
	Last point of CQT still unaddressed -- computationally expensive. Alternative: warped-frequency STFT based on nonuniform FFT to construct computationally cheaper transforms with arbitrary (mel, bark, constant-q/octave) frequency scales, built from the FFT + frequency warping operators (nonuniform FFT):
	\begin{itemize}
		\item
			Sharp transient resolution + nonlinear frequency resolution \footcite{warpwabnik}
		\item
			Low-error reconstructions proposed by \footcite{makur2008} (who gave me source code)
		\item
			Bark/ERB warping is known\footcite{barkerb}, better approximations proposed in \footcite{betterwarp}
		\item
			Constant-Q frequency warping has been described \footcite{cqwarp}
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Warped-STFT CQT simplified}
	Take constant-Q warp mapping of \footcite{cqwarp}. Check if \footcite{betterwarp} is applicable, if so use that. Use this warping in \footcite{makur2008} implementation (for which I have MATLAB source code, so I just need to transliterate it to C + Python). 
	Compare above warped-CQT to real NSGT-CQT in terms of:
	\begin{itemize}
		\item
			Computational cost
		\item
			Resulting frequency bins (since frequency warping is an approximation of the desired constant-Q, not precisely like the NSGT)
		\item
			Reconstruction error. Maybe it's fine for analysis but not synthesis (so not good for music sep, but good for onset detection)
		\item
			Frequency scales -- similar params (bins = number of filterbank, modifying the warp coefficient = approximations of mel, bark, octave, and other f scales)
	\end{itemize}
	Might be the first warped-STFT library on GitHub (I have looked)
\end{frame}

\end{document}
