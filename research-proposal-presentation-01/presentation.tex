\documentclass[usenames,dvipsnames]{beamer}
\usetheme{Boadilla}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{multimedia}
\usepackage{fancyvrb}
\usepackage{multicol}
\usepackage{optparams}
\usepackage{adjustbox}
\usepackage{tikz}
\usetikzlibrary{shapes,positioning}
\newcommand{\foo}{\hspace{-2.3pt}$\bullet$ \hspace{5pt}}
\usepackage{subfig}
\usepackage[
    backend=biber,
    natbib=true,
    style=numeric,
    sorting=none,
    style=verbose-ibid,
    maxcitenames=1, %remove this outside of toy presentations
]{biblatex}
\addbibresource{citations.bib}
\usepackage{pgfpages}
\usepackage{xcolor}
\definecolor{ao(english)}{rgb}{0.0, 0.5, 0.0}
\definecolor{burgundy}{rgb}{0.5, 0.0, 0.13}
%\setbeameroption{show notes}
%\setbeameroption{show notes on second screen=right}
\setbeameroption{hide notes}

\title{Better spectrograms for onset detection and music source separation}
\subtitle{MA Thesis research proposal}
\author{Sevag Hanssian}
\institute{DDMAL, McGill}
\setbeamertemplate{navigation symbols}{}

\AtEveryBibitem{%
  \clearfield{pages}%
  \clearfield{volume}%
  \clearfield{number}%
}

\renewbibmacro{in:}{}

\AtEveryCitekey{%
  \clearfield{pages}%
  \clearfield{volume}%
  \clearfield{number}%
  \clearfield{doi}%
  \clearfield{journal}%
  \clearfield{booktitle}%
}

\begin{document}

\begin{frame}
\maketitle
\end{frame}

\begin{frame}
	\frametitle{My own goals}
	Motivating musical applications based on what I like working on:
	\begin{enumerate}
		\item
			Onset detection (actually, beat tracking -- but onset detection is more relevant to time-frequency analysis vs. beat tracking frontend)
		\item
			Music source separation
	\end{enumerate}
	What I want to do:
	\begin{enumerate}
		\item
			Hypothesis -- ``swap STFT-based spectrogram with a better one in music source separation and onset detection, and get better results''
		\item
			Why NSGT? perfectly invertible, rectangular time-frequency matrix, which can be used to create a spectrogram, with arbitrary frequency scales. Can use arbitrary frequency bands e.g. mel/bark/octave/log (octave NSGT == CQT)
		\item
			Get a publishable result by beating the SOTA in something
	\end{enumerate}
	Skills I want to gain or exercise:
	\begin{enumerate}
		\item
			Performance computing (Python, C, CUDA, GPU, etc.)
		\item
			Machine/deep learning
	\end{enumerate}
\end{frame}

\begin{frame}
	\frametitle{Judith Brown CQT -- classic paper}
	Classic paper by \footcite{jbrown}, creating a transform which maintained a constant ratio of frequency to frequency resolution:
\begin{itemize}
	\item
		Harmonics of f0 created by musical instruments have a consistent spacing in the log scale (\textit{constant pattern})
	\end{itemize}
	\begin{figure}[ht]
		\vspace{-0.75em}
		\centering
		\subfloat[Linear-frequency DFT]{\includegraphics[height=3cm]{../latex/violindft.png}}
		\hspace{0.5em}
		\subfloat[Constant-Q transform]{\includegraphics[height=3cm]{../latex/violincqt.png}}
		\caption{Violin playing the diatonic scale, $G_{3} \text{(196Hz)} - G_{5} \text{(784Hz)}$}
	\end{figure}
\end{frame}

\begin{frame}
	\frametitle{Klapuri CQT}
	Klapuri's CQT implementation is used in librosa, and up until recently, in MATLAB's CQT. According to \footcite{cqtklapuri}, ``the CQT is well-motivated from both musical and perceptual viewpoints'':
	\begin{enumerate}
		\item
			\textbf{Frequency spacing for music:} Fundamental frequencies (F0s) of the tones in Western music are geometrically spaced
		 \item
			 \textbf{Frequency spacing for human psychoacoustic auditory system:} From auditory perspective, the frequency resolution of the peripheral hearing system of humans is approx constant-Q (cites B. C. J. Moore)
		 \item
			 \textbf{Sharp transient/temporal resolution:} From perceptual audio coding (cites AAC codec from ISO/IEC), shortest transform window lengths are $\approx$ 3ms to retain high quality, whereas higher frequency resolution is required to carry out coding at low frequencies
		\item
			Contrast with the conventional DFT which has linearly spaced frequency bins and cannot satisfy the \textbf{varying tf resolution} requirements over the wide range of audible frequencies
	\end{enumerate}
\end{frame}

\begin{frame}
	\frametitle{Problems so far}
	Why is the CQT not popular and used everywhere in place of the STFT? According to \footcite{cqtklapuri}:
	\begin{itemize}
		\item
			Computational efficiency - CQT is expensive (jbrown, jbrown + msp paper, followed by klapuri)
		\item
			Imperfect reconstruction - jbrown's is not invertible. Klapuri has error of $10^{-3}$, or 55dB reconstruction - used in librosa. not bad, not good
		\item
			CQT produces a data structure that is more difficult to work with than the time-frequency matrix (spectrogram) obtained by using the STFT in successive time frames.\\
			The last problem is due to the fact that in CQT, the time resolution varies for different frequency bins, in effect meaning that the ``sampling'' of different frequency bins is not synchronized
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{D{\"o}rfler music transform}
	According to \footcite{doerflerphd}, a good transform for music must satisfy two properties (satisfied by two STFTs with two different window size):
\begin{itemize}
	\item
		\textit{Transients} are important musically, driving instrument identification and temporal events such as beats. As transients and broadband signals occur in the high frequency range, good time resolution in that range allows clearer identification of transient events.
	\item
		 Notes in the low frequency lay the harmonic basis of the song, requiring very fine frequency resolution.
\end{itemize}
	Leads to a single transform, CQT based on the NSGT -- perfect reconstruction using frame theory\footcite{balazs, invertiblecqt}, now used in MATLAB wavelet toolbox
\end{frame}

\begin{frame}
	\frametitle{Story so far}
	CQT can be good for music:
	\begin{enumerate}
		\item
			Constant-Q frequency spacing, good for Western musical scales and psychoacoustic system both
		\item
			Fine temporal resolution in the high frequency range for transients (attacks, percussion), fine frequency resolution in the low frequency range (for harmonic basis)
	\end{enumerate}
	Some CQT downsides as a STFT replacement are mitigated:
	\begin{enumerate}
		\item
			Perfect inversion solved by NSGT \footcite{invertiblecqt}. Python library: \href{https://github.com/grrrr/nsgt}{https://github.com/grrrr/nsgt}
		\item
			Make it look like an STFT in a rectangular matrix: both contemporary methods do this \footcite{cqtklapuri}, \footcite{invertiblecqt}
		\item
			Still computationally more expensive than the STFT
	\end{enumerate}
\end{frame}

\begin{frame}
	\frametitle{Refined hypotheses}
	\textbf{Music source separation}\\
	Source separation depends on sparsity of musical sources \footcite{musicsepgood}. Having the octave scale might help distinguish musical instrument sources more strongly (e.g. think back on jbrown's violin diagram)\\
	Transients are also important in source separation \footcite{transientsep}, and the CQT inherently contains sharp temporal/transient resolution\\
	\vspace{1em}
	\textbf{Onset detection}\\
	Beat tracking largely depends on onsets, and sharper transient resolution and well-defined notes on a musical scale could allow for better distinguishing of both percussive and non-percussive onsets. Clear SOTA to beat
\end{frame}


\begin{frame}
	\frametitle{Chapter 1 -- time-frequency analysis of music signals and the STFT}
	Intro to discrete-time audio signals, sample rate, Fourier transform, frequency/spectral analysis\\\ \\
	Gabor time-frequency uncertainty principal (and how we have to trade off time vs. frequency in the spectrogram), Gabor transform i.e. the first published use of the STFT, origins of the windowed FFT aka STFT (independently discovered but now merged in a unified theory)\\\ \\
	Common STFT operations or post-processing -- magnitude spectrograms, power spectrograms, mel spectrograms, log spectrograms, mfcc\\\ \\
	Relation to music e.g. large window sizes are used for harmonic instruments (find sources to corroborate this), small window sizes used for percussion (e.g. in music source separation this is very common and i wrote an entire report on this in 622)
\end{frame}

\begin{frame}
	\frametitle{Chapter 2 -- the CQT and NSGT for varying time-frequency analysis}
	History of CQT (jbrown, klapuri, nsgt). NSGT and how the CQT can be written as the NSGT with octave (and log/mel/bark) frequency scales\\\ \\
	Relation to the STFT -- time axis, frequency axis, coefficient values. Dimensionality -- e.g. $N \times M$  STFT matrix $\rightarrow$ $? \times ?$ CQT matrix. Computation: describe how many FFTs are applied, how many windows/filterbank\\\ \\
	Time-frequency properties, quantified -- e.g. ``with a 24-bin CQT, it has 1.3ms transient resolution in the frequency range f1-f2'' Relate this to music, e.g. ``percussion is known to have an attack time of 1.3ms'' or how a wide frequency range is necessary for bass guitar analysis\\
Params: Frequency scales: octave, mel, bark, log. Fmin: 20, 27.5, 32.7, 57, 80 Bins: bins-per-octave, or total bins. 12, 24, 48, 96 are shown in paper -- can go higher e.g. 120, 168. compare to known pitch scales or music instrument frequencies
\end{frame}

\begin{frame}
	\frametitle{Chapter 3 -- CQT for onset detection}
	Experiment idea (\textcolor{red}{\textbf{UNVALIDATED}}) - but there is precedent\footcite{beatnsgt}:
	\begin{enumerate}
		\item
			This paper: \href{https://www.diva-portal.org/smash/get/diva2:1338850/FULLTEXT02}{https://www.diva-portal.org/smash/get/diva2:1338850/FULLTEXT02} reproduces B{\"o}ck's SOTA CNN and RNN architectures for onset detection
		\item
			Both architectures use 3 STFTs as input with different window sizes (to vary time-frequency resolution)
		\item
			\textbf{hypothesis} single CQT has enough time-frequency information as 3 mixed-window STFTs, reducing the network size. maybe the improved transient and clarity of musical notes are beneficial (in fact, they already use log-scale spectrograms (logarithmic = constant-Q/octave) to improve results)
		\item
			First, redo paper recreation -- i.e, get the expected 86\% and 85\% RNN and CNN onset detection F-score with the standard 3 STFT model. Then, replace with single-CQT (or multi-CQT) architecture and see what happens
	\end{enumerate}
\end{frame}

\begin{frame}
	\frametitle{Onset detection -- ML skills}
	\begin{itemize}
		\item
			Nestor has been giving Junhao good tips on exactly/100\% reproducible ML research
		\item
			E.g. random number seed, batches, epochs, learning rate, etc. all committed to git repo
		\item
			Onset detection = my chance to apply the same rigor, and also learn more about deep learning best practises
		\item
			Generate 100\% reproducible variants of:
			\begin{enumerate}
				\item
					Reference RNN/CNN of B{\"o}ck
				\item
					CQT variants (mel, octave, bark, whatever)
			\end{enumerate}
		\item
			Compare things like error, accuracy, learning convergence, size of network, etc.
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Chapter 4 -- CQT for music source separation}
	Idea: replace STFT with CQT in source separation (\textcolor{ForestGreen}{\textbf{VALIDATED}})\\
	\vspace{0.5em}
	Without actually working on any single model, we can focus on the IRM -- (oracle) ideal ratio mask, representing the theoretical  best performance of spectral masking based music source separation algorithms \footcite{irm}, \footcite{sigsep2018}, \footcite{vincent07}\\
	\vspace{0.5em}
	Hypothesis: ``is it possible to surpass the best possible music source separation performance based on spectral masking by using CQT masking instead of STFT?''\\
	\vspace{0.5em}
	Bleeding edge -- today, best waveform based NNs (e.g. demucs) tout that they surpassed the previous SOTA spectrogram-based models (2018-2019) by beating the IRM. Tagline of new SOTA end-to-end waveform based models is ``surpassing ideal time-frequency mask''
\end{frame}

\begin{frame}
	\frametitle{Music sep -- computational skills}
	\begin{itemize}
		\item
			I have forked nsgt and SigSep mus-eval code to apply CUDA with cupy wherever possible (did some line-by-line profiling to find code hotspots, typically in the fft/ifft routines -- unsurprising)
		\item
			MUSDB18-HQ test set has 51 tracks
		\item
			Got computation time per track of MUSDB18-HQ down from 3 minutes 20 seconds, to under 30 seconds with the following tweaks:
			\begin{enumerate}
				\item
					float32/complex64 instead of 64/128
				\item
					CUDA/cupy-accelerated NSGT
				\item
					CUDA/cupy-accelerated BSS metrics
				\item
					Mono-channel testbench, not stereo (minor impact on results, halves computation time)
				\item
					All of this worth discussing in the same chapter? ``Chapter 4.3 performance optimizations necessary to run giant testbench'', cite cupy etc.
			\end{enumerate}
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Music source separation objective evaluation}
	Evaluations not based on human subjective analysis:
	\begin{itemize}
		\item
			Industry standard is BSS \footcite{bss} used in SiSec 2018 campaign for music source separation \footcite{sigsep2018}. BSS is used for recently published top source separation models -- even in bleeding-edge waveform-based end-to-end neural waveform models: \href{https://github.com/facebookresearch/demucs}{https://github.com/facebookresearch/demucs}
		\item
			Industry standard dataset is MUSDB18 and MUSDB18-HQ \footcite{musdb18, musdb18-hq}
		\item
			Used both in 622 so I'm equipped to evaluate
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Music source separation -- example evaluation}
	\begin{itemize}
		\item
			Forked bss eval + nsgt and modified both to use GPU (with CUDA/cupy) to speed up evaluation time (for a single track) from 3.5 minutes down to 0.5 s -- allows for a much bigger testbench
		\item
			Based on sisec's evaluation + boxplot code from the SiSec 2018 paper, e.g.:\\
			\includegraphics[height=3.5cm]{./irm_boxplot_example.png}
		\item
			Plan: compute IRM,IBM\{1,2\} for STFT 2048 (default) (should I mix window sizes here?) followed by optimal NSGT configurations -- take median scores to see how they across bins, frequency scale, fmin
	\end{itemize}
\end{frame}

\begin{frame}[fragile]
	\frametitle{Option 1 (outdated) -- manually defined parameters}
	custom json format for defining testcases:
	\begin{Verbatim}[fontsize=\tiny]
	sevagh:oracle-cqt $ cat config_octave.json
	{
	  "stft_configs": {
	    "window_sizes": [2048]
	  },
	  "nsgt_configs": {
	    "bins": [12, 24, 48, 96, 120, 168],
	    "fmin": [20, 27.5, 32.7, 57, 80],
	    "fmax": [22050],
	    "scale": ["oct"]
	  }
	}
	sevagh:oracle-cqt $ cat config_mel.json
	{
	  "stft_configs": {
	    "window_sizes": [2048]
	  },
	  "nsgt_configs": {
	    "bins": [12, 24, 48, 96, 120, 168],
	    "fmin": [20, 27.5, 32.7, 57, 80],
	    "fmax": [22050],
	    "scale": ["mel"]
	  }
	}
	\end{Verbatim}
\end{frame}

\begin{frame}
	\frametitle{Option 2 -- grid search for optimal NSGT parameters}
	\begin{itemize}
		\item
			Define frequency scales as choice of octave (aka log2), mel, bark
		\item
			Define bins as integers between 12 and 200
		\item
			Define fmin between 20hz (psychoacoustic low limit) and maybe 100hz? (gotta stop somewhere). jumps in, cents? 0.1 hz?
		\item
			Fmax is fixed at 22050 (for performance and nyquist reasons)
		\item
			Metric to minimize is actually 16 metrics - vocal/drum/other/accompaniment SDR/SAR/SIR/ISR (same as sisec)
		\item
			sklearn GridSearchCV
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Chapter 5 -- results, discussion, conclusion}
	tl;dr thesis:
	\begin{itemize}
		\item
			\textbf{Chapter 1:} Music analysis with the STFT leads to necessary tradeoff of time and frequency resolution (due to theoretical limitations of TF analysis). However, spectrogram/STFT is widely used and ubiquitous
		\item
			\textbf{Chapter 2:} the CQT better represents some musical properties, and can replace the STFT-spectrogram in-place in many algorithms. many configurations of CQ-NSGT (freq range, octave scales, etc.)
		\item
			\textbf{Chapter 3:} Show the success of the NSGT-based (perfect inversion) CQT in SOTA neural network for \textbf{onset detection}
		\item
			\textbf{Chapter 4:} see whether we can surpass the theoretical maximum performance/IRM of spectrogram-based \textbf{music source separation} with the CQT (many configs)
		\item
			\textbf{Chapter 5:} discuss and conclude
	\end{itemize}
	\textcolor{red}{\textbf{is this enough to constitute a thesis?}}
\end{frame}

\begin{frame}
	\frametitle{Publishing}
	\textbf{1. Surpassing music source separation ideal masking with NSGT}
	\begin{itemize}
		\item
			I have been using open-source code of SigSep, aka Antoine Liutkus and Fabian-Robert St{\"o}ter
		\item
			Produce minimal github repo showing proof that it works and surpasses the STFT with a smaller dimension transform
		\item
			Short and sweet result, 100\% reproducible, analytic (not machine learning)
		\item
			I can write a short, 2-column arXiv paper for the CQT ratio mask and request them to review it
		\item
			Embed this directly as a chapter in the thesis? appendix? or rewrite the same material in a more verbose thesis/chapter style?
		\item
			arXiv + plan for a real conference/journal to submit to?
	\end{itemize}
	\textbf{2. SOTA onset detection with CQT}
	Too soon to tell -- TBD after initial experiments
\end{frame}

\begin{frame}
	\frametitle{Questions}
	\begin{itemize}
		\item
			Copying large parts of past works and reports wholesale? Is that self/auto-plagiarism? Should I always rephrase/rewrite, even if it's my own work
		\item
			GPS grad progress report:\\
			\begin{quote}
			For a first report, students complete the \textbf{Objectives} box only.
			\end{quote}
			Objectives:
			\begin{enumerate}
				\item
					Prepare music separation ideal mask chapter of thesis (full results, metrics plotted per CQT parameter e.g. by bin size, by fmin) (\textbf{chapter 4})
				\item
					Start preparing Onset detection experiments -- recreate baseline F-scores with fully reproducible training + evaluation (preparing for CQT substitution) (\textbf{chapter 3})
			\end{enumerate}
			After success of these two objectives (ch 3, 4), I work add 1 and 2 (theoretical intro) and 5 (conclusion/dicussion) between summer and fall -- finish up early?
	\end{itemize}
\end{frame}

\end{document}
